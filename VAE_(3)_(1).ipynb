{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharath2805/Bharath2805/blob/main/VAE_(3)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaHNUDG1Tx6T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AvaxkEeWT7OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mpaG73sPT-hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMG2VSf3T7Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Parameters\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "latent_dim = 50  # Dimensionality of the latent space\n",
        "image_folder = '/content/sample_data/jpeg'  # Path to the folder containing images\n",
        "\n",
        "# Data loading and preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    image_folder,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMO54UelT7Ts",
        "outputId": "e7f19cc9-5500-4831-c031-fdb03b291160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder\n",
        "encoder_inputs = layers.Input(shape=(img_height, img_width, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "# Reparameterization trick to sample from the learned distribution\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Define the encoder model\n",
        "encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n"
      ],
      "metadata": {
        "id": "vefG0eeeT7We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the decoder\n",
        "latent_inputs = layers.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(8 * 8 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((8, 8, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)  # Adjusted\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Define the decoder model\n",
        "decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n"
      ],
      "metadata": {
        "id": "wUG-ajcdeSys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE model\n",
        "outputs = decoder(encoder(encoder_inputs)[2])\n",
        "vae = models.Model(encoder_inputs, outputs, name=\"vae\")\n",
        "\n",
        "# VAE Loss\n",
        "reconstruction_loss = losses.binary_crossentropy(encoder_inputs, outputs) * img_height * img_width\n",
        "kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "vae_loss = reconstruction_loss + kl_loss\n",
        "vae.add_loss(vae_loss)\n"
      ],
      "metadata": {
        "id": "jPC69p3ceS1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the VAE model\n",
        "vae.compile(optimizer=optimizers.Adam())\n",
        "\n",
        "# Train the VAE model\n",
        "vae.fit(train_generator, epochs=10, steps_per_epoch=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "uUig0xrCeS4Z",
        "outputId": "f7b06615-dd16-4483-9ad2-e8c21686d52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c908dc50e167>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the VAE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;34m\"Asked to retrieve element {idx}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\"but the Sequence \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "np3f7OkUfWl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Hkqpd-tfWoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhIY7XDUfWrT",
        "outputId": "85f31e3c-eae7-45a5-a2f5-15be1712a0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 32\n",
        "latent_dim = 50\n",
        "img_size = 128\n",
        "\n",
        "# Create a directory to save generated images\n",
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(root)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root, self.images[index])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load custom dataset\n",
        "dataset = CustomDataset(root='/content/sample_data/jpeg', transform=transform)\n",
        "\n",
        "# Create data loader\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*32*32, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim * 2)  # Two outputs for mean and log variance\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64*32*32),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 32, 32)),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()  # Output range [0, 1]\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        z_params = self.encoder(x)\n",
        "        mu, logvar = torch.chunk(z_params, 2, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # Decode\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction, mu, logvar\n",
        "\n",
        "# Create the VAE model\n",
        "model = VAE().to(device)\n",
        "\n",
        "# Loss function\n",
        "def loss_function(reconstruction, target, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(reconstruction, target, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, data in enumerate(data_loader):\n",
        "        img = data.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        reconstruction, mu, logvar = model(img)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(reconstruction, img, mu, logvar)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, batch_idx+1, len(data_loader), loss.item()))\n",
        "\n",
        "    # Save generated images\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        generated_images = model.decoder(z).cpu()\n",
        "        save_image(generated_images, os.path.join(sample_dir, 'generated_images-{}.png'.format(epoch+1)))\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'vae_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "mG6k9-w4fWt9",
        "outputId": "fcf0ddcc-8c39-4609-8572-9151ce680d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [422/1000], Step [1/4], Loss: 316128.9688\n",
            "Epoch [423/1000], Step [1/4], Loss: 309320.3750\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1841a151c8fb>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GrCKtxgGfWw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**working code**\n"
      ],
      "metadata": {
        "id": "CPv3nsw0sPF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "m_UbuQrZfWzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f82327-46b7-4114-855d-c562bece89a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "4aIIXljIfW2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "img_size = 64\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 2000\n",
        "\n",
        "# Create a directory to save generated images\n",
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(root)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root, self.images[index])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load custom dataset\n",
        "dataset = CustomDataset(root='/content/sample_data/dataset', transform=transform)\n",
        "\n",
        "# Create data loader\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim * 2)  # Two outputs for mean and log variance\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 128*8*8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()  # Output range [0, 1]\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        z_params = self.encoder(x)\n",
        "        mu, logvar = torch.chunk(z_params, 2, dim=1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # Decode\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction, mu, logvar\n",
        "\n",
        "# Create the VAE model\n",
        "model = VAE().to(device)\n",
        "\n",
        "# Loss function\n",
        "def loss_function(reconstruction, target, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(reconstruction, target, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, data in enumerate(data_loader):\n",
        "        img = data.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        reconstruction, mu, logvar = model(img)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(reconstruction, img, mu, logvar)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, batch_idx+1, len(data_loader), loss.item()))\n",
        "\n",
        "    # Save generated images\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        generated_images = model.decoder(z).cpu()\n",
        "        save_image(generated_images, os.path.join(sample_dir, 'generated_images-{}.png'.format(epoch+1)))\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'vae_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtinHuMfW5o",
        "outputId": "1b72e06d-f4e9-4779-a9ef-beaede0e34b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2000], Step [1/3], Loss: 544621.9375\n",
            "Epoch [2/2000], Step [1/3], Loss: 544635.8125\n",
            "Epoch [3/2000], Step [1/3], Loss: 544523.3125\n",
            "Epoch [4/2000], Step [1/3], Loss: 543904.0625\n",
            "Epoch [5/2000], Step [1/3], Loss: 543453.2500\n",
            "Epoch [6/2000], Step [1/3], Loss: 543625.9375\n",
            "Epoch [7/2000], Step [1/3], Loss: 543194.3125\n",
            "Epoch [8/2000], Step [1/3], Loss: 542580.8750\n",
            "Epoch [9/2000], Step [1/3], Loss: 541837.4375\n",
            "Epoch [10/2000], Step [1/3], Loss: 540598.5625\n",
            "Epoch [11/2000], Step [1/3], Loss: 539529.6250\n",
            "Epoch [12/2000], Step [1/3], Loss: 538794.5625\n",
            "Epoch [13/2000], Step [1/3], Loss: 537065.1875\n",
            "Epoch [14/2000], Step [1/3], Loss: 536509.3750\n",
            "Epoch [15/2000], Step [1/3], Loss: 534958.5625\n",
            "Epoch [16/2000], Step [1/3], Loss: 535212.0000\n",
            "Epoch [17/2000], Step [1/3], Loss: 532741.8125\n",
            "Epoch [18/2000], Step [1/3], Loss: 532708.6875\n",
            "Epoch [19/2000], Step [1/3], Loss: 532468.7500\n",
            "Epoch [20/2000], Step [1/3], Loss: 532274.8125\n",
            "Epoch [21/2000], Step [1/3], Loss: 531941.6875\n",
            "Epoch [22/2000], Step [1/3], Loss: 530706.1250\n",
            "Epoch [23/2000], Step [1/3], Loss: 530759.0625\n",
            "Epoch [24/2000], Step [1/3], Loss: 530426.0625\n",
            "Epoch [25/2000], Step [1/3], Loss: 531489.8750\n",
            "Epoch [26/2000], Step [1/3], Loss: 530386.1250\n",
            "Epoch [27/2000], Step [1/3], Loss: 531379.2500\n",
            "Epoch [28/2000], Step [1/3], Loss: 531015.0000\n",
            "Epoch [29/2000], Step [1/3], Loss: 529889.1250\n",
            "Epoch [30/2000], Step [1/3], Loss: 529845.7500\n",
            "Epoch [31/2000], Step [1/3], Loss: 529600.5000\n",
            "Epoch [32/2000], Step [1/3], Loss: 529865.9375\n",
            "Epoch [33/2000], Step [1/3], Loss: 530344.0625\n",
            "Epoch [34/2000], Step [1/3], Loss: 529702.0625\n",
            "Epoch [35/2000], Step [1/3], Loss: 529277.3750\n",
            "Epoch [36/2000], Step [1/3], Loss: 529300.6250\n",
            "Epoch [37/2000], Step [1/3], Loss: 529436.8750\n",
            "Epoch [38/2000], Step [1/3], Loss: 528805.1250\n",
            "Epoch [39/2000], Step [1/3], Loss: 528875.1875\n",
            "Epoch [40/2000], Step [1/3], Loss: 528910.6875\n",
            "Epoch [41/2000], Step [1/3], Loss: 530017.2500\n",
            "Epoch [42/2000], Step [1/3], Loss: 528096.6250\n",
            "Epoch [43/2000], Step [1/3], Loss: 527177.8750\n",
            "Epoch [44/2000], Step [1/3], Loss: 528415.0625\n",
            "Epoch [45/2000], Step [1/3], Loss: 527442.1875\n",
            "Epoch [46/2000], Step [1/3], Loss: 526614.1875\n",
            "Epoch [47/2000], Step [1/3], Loss: 528305.3125\n",
            "Epoch [48/2000], Step [1/3], Loss: 528324.8125\n",
            "Epoch [49/2000], Step [1/3], Loss: 525648.4375\n",
            "Epoch [50/2000], Step [1/3], Loss: 526085.6250\n",
            "Epoch [51/2000], Step [1/3], Loss: 525819.9375\n",
            "Epoch [52/2000], Step [1/3], Loss: 526393.9375\n",
            "Epoch [53/2000], Step [1/3], Loss: 525872.1875\n",
            "Epoch [54/2000], Step [1/3], Loss: 523408.8125\n",
            "Epoch [55/2000], Step [1/3], Loss: 522642.7812\n",
            "Epoch [56/2000], Step [1/3], Loss: 522437.1250\n",
            "Epoch [57/2000], Step [1/3], Loss: 523354.6250\n",
            "Epoch [58/2000], Step [1/3], Loss: 521587.6562\n",
            "Epoch [59/2000], Step [1/3], Loss: 520864.5625\n",
            "Epoch [60/2000], Step [1/3], Loss: 522265.0000\n",
            "Epoch [61/2000], Step [1/3], Loss: 520517.7500\n",
            "Epoch [62/2000], Step [1/3], Loss: 520115.3125\n",
            "Epoch [63/2000], Step [1/3], Loss: 522377.2188\n",
            "Epoch [64/2000], Step [1/3], Loss: 519358.0312\n",
            "Epoch [65/2000], Step [1/3], Loss: 519697.7500\n",
            "Epoch [66/2000], Step [1/3], Loss: 520952.5938\n",
            "Epoch [67/2000], Step [1/3], Loss: 520167.8750\n",
            "Epoch [68/2000], Step [1/3], Loss: 519634.4062\n",
            "Epoch [69/2000], Step [1/3], Loss: 520639.2500\n",
            "Epoch [70/2000], Step [1/3], Loss: 520951.6250\n",
            "Epoch [71/2000], Step [1/3], Loss: 520389.1562\n",
            "Epoch [72/2000], Step [1/3], Loss: 519526.8750\n",
            "Epoch [73/2000], Step [1/3], Loss: 520167.0938\n",
            "Epoch [74/2000], Step [1/3], Loss: 521508.6250\n",
            "Epoch [75/2000], Step [1/3], Loss: 521075.8125\n",
            "Epoch [76/2000], Step [1/3], Loss: 519397.7812\n",
            "Epoch [77/2000], Step [1/3], Loss: 519337.0938\n",
            "Epoch [78/2000], Step [1/3], Loss: 519906.5625\n",
            "Epoch [79/2000], Step [1/3], Loss: 518824.7188\n",
            "Epoch [80/2000], Step [1/3], Loss: 520904.8750\n",
            "Epoch [81/2000], Step [1/3], Loss: 518498.3438\n",
            "Epoch [82/2000], Step [1/3], Loss: 519719.0312\n",
            "Epoch [83/2000], Step [1/3], Loss: 519344.8125\n",
            "Epoch [84/2000], Step [1/3], Loss: 518121.3750\n",
            "Epoch [85/2000], Step [1/3], Loss: 518693.6562\n",
            "Epoch [86/2000], Step [1/3], Loss: 519332.4375\n",
            "Epoch [87/2000], Step [1/3], Loss: 519667.6875\n",
            "Epoch [88/2000], Step [1/3], Loss: 517685.3125\n",
            "Epoch [89/2000], Step [1/3], Loss: 518750.9688\n",
            "Epoch [90/2000], Step [1/3], Loss: 518726.0625\n",
            "Epoch [91/2000], Step [1/3], Loss: 518952.9375\n",
            "Epoch [92/2000], Step [1/3], Loss: 519180.0938\n",
            "Epoch [93/2000], Step [1/3], Loss: 519218.2188\n",
            "Epoch [94/2000], Step [1/3], Loss: 519596.4062\n",
            "Epoch [95/2000], Step [1/3], Loss: 520820.0312\n",
            "Epoch [96/2000], Step [1/3], Loss: 518654.2500\n",
            "Epoch [97/2000], Step [1/3], Loss: 520760.3750\n",
            "Epoch [98/2000], Step [1/3], Loss: 517313.5938\n",
            "Epoch [99/2000], Step [1/3], Loss: 519082.8125\n",
            "Epoch [100/2000], Step [1/3], Loss: 517786.8438\n",
            "Epoch [101/2000], Step [1/3], Loss: 519647.2500\n",
            "Epoch [102/2000], Step [1/3], Loss: 517940.8750\n",
            "Epoch [103/2000], Step [1/3], Loss: 518327.5312\n",
            "Epoch [104/2000], Step [1/3], Loss: 517870.0312\n",
            "Epoch [105/2000], Step [1/3], Loss: 518295.0938\n",
            "Epoch [106/2000], Step [1/3], Loss: 517249.5312\n",
            "Epoch [107/2000], Step [1/3], Loss: 517620.0312\n",
            "Epoch [108/2000], Step [1/3], Loss: 518113.2188\n",
            "Epoch [109/2000], Step [1/3], Loss: 520277.7500\n",
            "Epoch [110/2000], Step [1/3], Loss: 517926.1562\n",
            "Epoch [111/2000], Step [1/3], Loss: 518407.8125\n",
            "Epoch [112/2000], Step [1/3], Loss: 518686.8125\n",
            "Epoch [113/2000], Step [1/3], Loss: 516713.7188\n",
            "Epoch [114/2000], Step [1/3], Loss: 517465.5312\n",
            "Epoch [115/2000], Step [1/3], Loss: 516188.2500\n",
            "Epoch [116/2000], Step [1/3], Loss: 518531.0938\n",
            "Epoch [117/2000], Step [1/3], Loss: 515515.8125\n",
            "Epoch [118/2000], Step [1/3], Loss: 517424.3125\n",
            "Epoch [119/2000], Step [1/3], Loss: 518267.8125\n",
            "Epoch [120/2000], Step [1/3], Loss: 517135.0938\n",
            "Epoch [121/2000], Step [1/3], Loss: 516140.2500\n",
            "Epoch [122/2000], Step [1/3], Loss: 516974.0938\n",
            "Epoch [123/2000], Step [1/3], Loss: 517797.5000\n",
            "Epoch [124/2000], Step [1/3], Loss: 516729.1562\n",
            "Epoch [125/2000], Step [1/3], Loss: 517892.5312\n",
            "Epoch [126/2000], Step [1/3], Loss: 518267.2500\n",
            "Epoch [127/2000], Step [1/3], Loss: 517709.4688\n",
            "Epoch [128/2000], Step [1/3], Loss: 516362.1875\n",
            "Epoch [129/2000], Step [1/3], Loss: 518653.8750\n",
            "Epoch [130/2000], Step [1/3], Loss: 515581.5938\n",
            "Epoch [131/2000], Step [1/3], Loss: 516937.6250\n",
            "Epoch [132/2000], Step [1/3], Loss: 517310.8438\n",
            "Epoch [133/2000], Step [1/3], Loss: 515778.0312\n",
            "Epoch [134/2000], Step [1/3], Loss: 515647.1875\n",
            "Epoch [135/2000], Step [1/3], Loss: 515421.1562\n",
            "Epoch [136/2000], Step [1/3], Loss: 516369.3125\n",
            "Epoch [137/2000], Step [1/3], Loss: 515771.3750\n",
            "Epoch [138/2000], Step [1/3], Loss: 517023.6875\n",
            "Epoch [139/2000], Step [1/3], Loss: 517554.5625\n",
            "Epoch [140/2000], Step [1/3], Loss: 515015.0312\n",
            "Epoch [141/2000], Step [1/3], Loss: 516891.7500\n",
            "Epoch [142/2000], Step [1/3], Loss: 517705.3438\n",
            "Epoch [143/2000], Step [1/3], Loss: 516934.3750\n",
            "Epoch [144/2000], Step [1/3], Loss: 517334.5625\n",
            "Epoch [145/2000], Step [1/3], Loss: 515544.4688\n",
            "Epoch [146/2000], Step [1/3], Loss: 516265.0938\n",
            "Epoch [147/2000], Step [1/3], Loss: 516848.2812\n",
            "Epoch [148/2000], Step [1/3], Loss: 518016.2500\n",
            "Epoch [149/2000], Step [1/3], Loss: 514409.1250\n",
            "Epoch [150/2000], Step [1/3], Loss: 515363.2500\n",
            "Epoch [151/2000], Step [1/3], Loss: 516372.0000\n",
            "Epoch [152/2000], Step [1/3], Loss: 516489.5312\n",
            "Epoch [153/2000], Step [1/3], Loss: 517437.8125\n",
            "Epoch [154/2000], Step [1/3], Loss: 515735.7812\n",
            "Epoch [155/2000], Step [1/3], Loss: 516607.5625\n",
            "Epoch [156/2000], Step [1/3], Loss: 516102.4688\n",
            "Epoch [157/2000], Step [1/3], Loss: 517327.4688\n",
            "Epoch [158/2000], Step [1/3], Loss: 516493.2812\n",
            "Epoch [159/2000], Step [1/3], Loss: 515922.5938\n",
            "Epoch [160/2000], Step [1/3], Loss: 515693.0625\n",
            "Epoch [161/2000], Step [1/3], Loss: 515392.0312\n",
            "Epoch [162/2000], Step [1/3], Loss: 515990.6250\n",
            "Epoch [163/2000], Step [1/3], Loss: 515398.3750\n",
            "Epoch [164/2000], Step [1/3], Loss: 514400.0625\n",
            "Epoch [165/2000], Step [1/3], Loss: 517152.8750\n",
            "Epoch [166/2000], Step [1/3], Loss: 517763.5625\n",
            "Epoch [167/2000], Step [1/3], Loss: 515204.3750\n",
            "Epoch [168/2000], Step [1/3], Loss: 515355.5625\n",
            "Epoch [169/2000], Step [1/3], Loss: 516238.8438\n",
            "Epoch [170/2000], Step [1/3], Loss: 515716.3750\n",
            "Epoch [171/2000], Step [1/3], Loss: 514777.1875\n",
            "Epoch [172/2000], Step [1/3], Loss: 513844.3125\n",
            "Epoch [173/2000], Step [1/3], Loss: 516351.1250\n",
            "Epoch [174/2000], Step [1/3], Loss: 518058.3438\n",
            "Epoch [175/2000], Step [1/3], Loss: 514165.6250\n",
            "Epoch [176/2000], Step [1/3], Loss: 515966.0625\n",
            "Epoch [177/2000], Step [1/3], Loss: 515387.9062\n",
            "Epoch [178/2000], Step [1/3], Loss: 514556.1562\n",
            "Epoch [179/2000], Step [1/3], Loss: 515148.4062\n",
            "Epoch [180/2000], Step [1/3], Loss: 513538.0938\n",
            "Epoch [181/2000], Step [1/3], Loss: 513332.0938\n",
            "Epoch [182/2000], Step [1/3], Loss: 516377.0000\n",
            "Epoch [183/2000], Step [1/3], Loss: 513173.3438\n",
            "Epoch [184/2000], Step [1/3], Loss: 517447.2500\n",
            "Epoch [185/2000], Step [1/3], Loss: 513678.9688\n",
            "Epoch [186/2000], Step [1/3], Loss: 513972.5938\n",
            "Epoch [187/2000], Step [1/3], Loss: 516395.8125\n",
            "Epoch [188/2000], Step [1/3], Loss: 513888.6875\n",
            "Epoch [189/2000], Step [1/3], Loss: 516039.6562\n",
            "Epoch [190/2000], Step [1/3], Loss: 514919.3125\n",
            "Epoch [191/2000], Step [1/3], Loss: 512973.7500\n",
            "Epoch [192/2000], Step [1/3], Loss: 515031.6875\n",
            "Epoch [193/2000], Step [1/3], Loss: 513113.9375\n",
            "Epoch [194/2000], Step [1/3], Loss: 512550.6875\n",
            "Epoch [195/2000], Step [1/3], Loss: 515061.7812\n",
            "Epoch [196/2000], Step [1/3], Loss: 515306.6250\n",
            "Epoch [197/2000], Step [1/3], Loss: 515727.3125\n",
            "Epoch [198/2000], Step [1/3], Loss: 516307.6875\n",
            "Epoch [199/2000], Step [1/3], Loss: 514006.4375\n",
            "Epoch [200/2000], Step [1/3], Loss: 514378.0312\n",
            "Epoch [201/2000], Step [1/3], Loss: 514325.0938\n",
            "Epoch [202/2000], Step [1/3], Loss: 515756.0938\n",
            "Epoch [203/2000], Step [1/3], Loss: 517035.1250\n",
            "Epoch [204/2000], Step [1/3], Loss: 516830.3750\n",
            "Epoch [205/2000], Step [1/3], Loss: 512916.5312\n",
            "Epoch [206/2000], Step [1/3], Loss: 514371.0000\n",
            "Epoch [207/2000], Step [1/3], Loss: 514949.0938\n",
            "Epoch [208/2000], Step [1/3], Loss: 513425.8125\n",
            "Epoch [209/2000], Step [1/3], Loss: 514800.6562\n",
            "Epoch [210/2000], Step [1/3], Loss: 513901.9062\n",
            "Epoch [211/2000], Step [1/3], Loss: 511775.8750\n",
            "Epoch [212/2000], Step [1/3], Loss: 511738.3438\n",
            "Epoch [213/2000], Step [1/3], Loss: 513423.6562\n",
            "Epoch [214/2000], Step [1/3], Loss: 513669.4375\n",
            "Epoch [215/2000], Step [1/3], Loss: 515160.7812\n",
            "Epoch [216/2000], Step [1/3], Loss: 514884.3438\n",
            "Epoch [217/2000], Step [1/3], Loss: 513867.3750\n",
            "Epoch [218/2000], Step [1/3], Loss: 514679.0938\n",
            "Epoch [219/2000], Step [1/3], Loss: 514374.8438\n",
            "Epoch [220/2000], Step [1/3], Loss: 513682.5938\n",
            "Epoch [221/2000], Step [1/3], Loss: 513511.3438\n",
            "Epoch [222/2000], Step [1/3], Loss: 514130.2812\n",
            "Epoch [223/2000], Step [1/3], Loss: 513684.8125\n",
            "Epoch [224/2000], Step [1/3], Loss: 516278.1562\n",
            "Epoch [225/2000], Step [1/3], Loss: 515338.9062\n",
            "Epoch [226/2000], Step [1/3], Loss: 514666.1875\n",
            "Epoch [227/2000], Step [1/3], Loss: 513028.6875\n",
            "Epoch [228/2000], Step [1/3], Loss: 511230.2188\n",
            "Epoch [229/2000], Step [1/3], Loss: 512360.0938\n",
            "Epoch [230/2000], Step [1/3], Loss: 515127.6562\n",
            "Epoch [231/2000], Step [1/3], Loss: 512364.6250\n",
            "Epoch [232/2000], Step [1/3], Loss: 513091.3750\n",
            "Epoch [233/2000], Step [1/3], Loss: 514750.8438\n",
            "Epoch [234/2000], Step [1/3], Loss: 513246.3125\n",
            "Epoch [235/2000], Step [1/3], Loss: 514422.7812\n",
            "Epoch [236/2000], Step [1/3], Loss: 515449.8438\n",
            "Epoch [237/2000], Step [1/3], Loss: 511906.6562\n",
            "Epoch [238/2000], Step [1/3], Loss: 516163.3125\n",
            "Epoch [239/2000], Step [1/3], Loss: 515890.2500\n",
            "Epoch [240/2000], Step [1/3], Loss: 513565.5938\n",
            "Epoch [241/2000], Step [1/3], Loss: 511769.4375\n",
            "Epoch [242/2000], Step [1/3], Loss: 513265.3125\n",
            "Epoch [243/2000], Step [1/3], Loss: 514224.9688\n",
            "Epoch [244/2000], Step [1/3], Loss: 514482.2812\n",
            "Epoch [245/2000], Step [1/3], Loss: 511020.0000\n",
            "Epoch [246/2000], Step [1/3], Loss: 509988.1562\n",
            "Epoch [247/2000], Step [1/3], Loss: 515461.2500\n",
            "Epoch [248/2000], Step [1/3], Loss: 514306.6250\n",
            "Epoch [249/2000], Step [1/3], Loss: 514436.1250\n",
            "Epoch [250/2000], Step [1/3], Loss: 514460.0938\n",
            "Epoch [251/2000], Step [1/3], Loss: 510820.3125\n",
            "Epoch [252/2000], Step [1/3], Loss: 513528.5312\n",
            "Epoch [253/2000], Step [1/3], Loss: 513030.1562\n",
            "Epoch [254/2000], Step [1/3], Loss: 512048.6562\n",
            "Epoch [255/2000], Step [1/3], Loss: 511918.6562\n",
            "Epoch [256/2000], Step [1/3], Loss: 511707.4688\n",
            "Epoch [257/2000], Step [1/3], Loss: 512746.4375\n",
            "Epoch [258/2000], Step [1/3], Loss: 512950.6875\n",
            "Epoch [259/2000], Step [1/3], Loss: 510277.5938\n",
            "Epoch [260/2000], Step [1/3], Loss: 509861.0938\n",
            "Epoch [261/2000], Step [1/3], Loss: 512700.1562\n",
            "Epoch [262/2000], Step [1/3], Loss: 511719.1250\n",
            "Epoch [263/2000], Step [1/3], Loss: 513944.8438\n",
            "Epoch [264/2000], Step [1/3], Loss: 510967.5938\n",
            "Epoch [265/2000], Step [1/3], Loss: 514353.3438\n",
            "Epoch [266/2000], Step [1/3], Loss: 513158.0312\n",
            "Epoch [267/2000], Step [1/3], Loss: 512045.7188\n",
            "Epoch [268/2000], Step [1/3], Loss: 510022.1562\n",
            "Epoch [269/2000], Step [1/3], Loss: 512733.8438\n",
            "Epoch [270/2000], Step [1/3], Loss: 512904.1875\n",
            "Epoch [271/2000], Step [1/3], Loss: 512907.4688\n",
            "Epoch [272/2000], Step [1/3], Loss: 510567.6562\n",
            "Epoch [273/2000], Step [1/3], Loss: 513206.5000\n",
            "Epoch [274/2000], Step [1/3], Loss: 512319.9375\n",
            "Epoch [275/2000], Step [1/3], Loss: 510575.2812\n",
            "Epoch [276/2000], Step [1/3], Loss: 512994.1562\n",
            "Epoch [277/2000], Step [1/3], Loss: 511792.6875\n",
            "Epoch [278/2000], Step [1/3], Loss: 511581.8125\n",
            "Epoch [279/2000], Step [1/3], Loss: 511248.7500\n",
            "Epoch [280/2000], Step [1/3], Loss: 512212.4062\n",
            "Epoch [281/2000], Step [1/3], Loss: 512878.5000\n",
            "Epoch [282/2000], Step [1/3], Loss: 513107.6562\n",
            "Epoch [283/2000], Step [1/3], Loss: 511695.7812\n",
            "Epoch [284/2000], Step [1/3], Loss: 511061.2812\n",
            "Epoch [285/2000], Step [1/3], Loss: 513482.3750\n",
            "Epoch [286/2000], Step [1/3], Loss: 512753.5000\n",
            "Epoch [287/2000], Step [1/3], Loss: 511269.1875\n",
            "Epoch [288/2000], Step [1/3], Loss: 512166.0312\n",
            "Epoch [289/2000], Step [1/3], Loss: 507194.6250\n",
            "Epoch [290/2000], Step [1/3], Loss: 512349.7500\n",
            "Epoch [291/2000], Step [1/3], Loss: 510658.4062\n",
            "Epoch [292/2000], Step [1/3], Loss: 512893.0312\n",
            "Epoch [293/2000], Step [1/3], Loss: 513666.2812\n",
            "Epoch [294/2000], Step [1/3], Loss: 510626.3750\n",
            "Epoch [295/2000], Step [1/3], Loss: 510718.0938\n",
            "Epoch [296/2000], Step [1/3], Loss: 511719.4688\n",
            "Epoch [297/2000], Step [1/3], Loss: 510640.6250\n",
            "Epoch [298/2000], Step [1/3], Loss: 511042.5000\n",
            "Epoch [299/2000], Step [1/3], Loss: 512162.7188\n",
            "Epoch [300/2000], Step [1/3], Loss: 511789.6875\n",
            "Epoch [301/2000], Step [1/3], Loss: 512519.8438\n",
            "Epoch [302/2000], Step [1/3], Loss: 509511.0000\n",
            "Epoch [303/2000], Step [1/3], Loss: 512394.0625\n",
            "Epoch [304/2000], Step [1/3], Loss: 512781.8750\n",
            "Epoch [305/2000], Step [1/3], Loss: 513101.0938\n",
            "Epoch [306/2000], Step [1/3], Loss: 510878.6562\n",
            "Epoch [307/2000], Step [1/3], Loss: 512529.4062\n",
            "Epoch [308/2000], Step [1/3], Loss: 509928.8438\n",
            "Epoch [309/2000], Step [1/3], Loss: 509329.8750\n",
            "Epoch [310/2000], Step [1/3], Loss: 509692.3438\n",
            "Epoch [311/2000], Step [1/3], Loss: 512327.7812\n",
            "Epoch [312/2000], Step [1/3], Loss: 511162.0938\n",
            "Epoch [313/2000], Step [1/3], Loss: 511471.5938\n",
            "Epoch [314/2000], Step [1/3], Loss: 510106.5312\n",
            "Epoch [315/2000], Step [1/3], Loss: 511497.6875\n",
            "Epoch [316/2000], Step [1/3], Loss: 511718.6562\n",
            "Epoch [317/2000], Step [1/3], Loss: 509882.7188\n",
            "Epoch [318/2000], Step [1/3], Loss: 511119.8750\n",
            "Epoch [319/2000], Step [1/3], Loss: 509165.1562\n",
            "Epoch [320/2000], Step [1/3], Loss: 509810.0625\n",
            "Epoch [321/2000], Step [1/3], Loss: 511297.6875\n",
            "Epoch [322/2000], Step [1/3], Loss: 509879.9062\n",
            "Epoch [323/2000], Step [1/3], Loss: 512043.7812\n",
            "Epoch [324/2000], Step [1/3], Loss: 512290.1250\n",
            "Epoch [325/2000], Step [1/3], Loss: 511907.2812\n",
            "Epoch [326/2000], Step [1/3], Loss: 510256.7812\n",
            "Epoch [327/2000], Step [1/3], Loss: 508012.9375\n",
            "Epoch [328/2000], Step [1/3], Loss: 511380.4375\n",
            "Epoch [329/2000], Step [1/3], Loss: 510046.6875\n",
            "Epoch [330/2000], Step [1/3], Loss: 510233.5000\n",
            "Epoch [331/2000], Step [1/3], Loss: 509705.2500\n",
            "Epoch [332/2000], Step [1/3], Loss: 509711.3438\n",
            "Epoch [333/2000], Step [1/3], Loss: 511296.5312\n",
            "Epoch [334/2000], Step [1/3], Loss: 511122.3125\n",
            "Epoch [335/2000], Step [1/3], Loss: 510528.5312\n",
            "Epoch [336/2000], Step [1/3], Loss: 509578.3125\n",
            "Epoch [337/2000], Step [1/3], Loss: 510976.5000\n",
            "Epoch [338/2000], Step [1/3], Loss: 512336.2188\n",
            "Epoch [339/2000], Step [1/3], Loss: 511935.3438\n",
            "Epoch [340/2000], Step [1/3], Loss: 512103.0625\n",
            "Epoch [341/2000], Step [1/3], Loss: 509758.4062\n",
            "Epoch [342/2000], Step [1/3], Loss: 511615.9688\n",
            "Epoch [343/2000], Step [1/3], Loss: 510512.2812\n",
            "Epoch [344/2000], Step [1/3], Loss: 510666.0625\n",
            "Epoch [345/2000], Step [1/3], Loss: 511237.7188\n",
            "Epoch [346/2000], Step [1/3], Loss: 512422.4062\n",
            "Epoch [347/2000], Step [1/3], Loss: 510379.0000\n",
            "Epoch [348/2000], Step [1/3], Loss: 511281.8125\n",
            "Epoch [349/2000], Step [1/3], Loss: 512701.5625\n",
            "Epoch [350/2000], Step [1/3], Loss: 510347.7812\n",
            "Epoch [351/2000], Step [1/3], Loss: 510155.0625\n",
            "Epoch [352/2000], Step [1/3], Loss: 509695.3125\n",
            "Epoch [353/2000], Step [1/3], Loss: 508192.5000\n",
            "Epoch [354/2000], Step [1/3], Loss: 511720.8438\n",
            "Epoch [355/2000], Step [1/3], Loss: 510046.5000\n",
            "Epoch [356/2000], Step [1/3], Loss: 509710.8438\n",
            "Epoch [357/2000], Step [1/3], Loss: 507962.2812\n",
            "Epoch [358/2000], Step [1/3], Loss: 509648.0938\n",
            "Epoch [359/2000], Step [1/3], Loss: 510196.5000\n",
            "Epoch [360/2000], Step [1/3], Loss: 509736.0000\n",
            "Epoch [361/2000], Step [1/3], Loss: 509525.6562\n",
            "Epoch [362/2000], Step [1/3], Loss: 508258.5625\n",
            "Epoch [363/2000], Step [1/3], Loss: 511096.1875\n",
            "Epoch [364/2000], Step [1/3], Loss: 509014.0938\n",
            "Epoch [365/2000], Step [1/3], Loss: 511794.1250\n",
            "Epoch [366/2000], Step [1/3], Loss: 507140.2812\n",
            "Epoch [367/2000], Step [1/3], Loss: 510360.3125\n",
            "Epoch [368/2000], Step [1/3], Loss: 509160.3125\n",
            "Epoch [369/2000], Step [1/3], Loss: 511107.3438\n",
            "Epoch [370/2000], Step [1/3], Loss: 509675.4062\n",
            "Epoch [371/2000], Step [1/3], Loss: 507754.5312\n",
            "Epoch [372/2000], Step [1/3], Loss: 509955.2500\n",
            "Epoch [373/2000], Step [1/3], Loss: 508673.8750\n",
            "Epoch [374/2000], Step [1/3], Loss: 509412.9375\n",
            "Epoch [375/2000], Step [1/3], Loss: 511433.2812\n",
            "Epoch [376/2000], Step [1/3], Loss: 508183.5312\n",
            "Epoch [377/2000], Step [1/3], Loss: 509685.8438\n",
            "Epoch [378/2000], Step [1/3], Loss: 507857.6875\n",
            "Epoch [379/2000], Step [1/3], Loss: 511077.3125\n",
            "Epoch [380/2000], Step [1/3], Loss: 510111.5938\n",
            "Epoch [381/2000], Step [1/3], Loss: 509537.0938\n",
            "Epoch [382/2000], Step [1/3], Loss: 510176.7500\n",
            "Epoch [383/2000], Step [1/3], Loss: 507034.8750\n",
            "Epoch [384/2000], Step [1/3], Loss: 508405.1875\n",
            "Epoch [385/2000], Step [1/3], Loss: 508985.8750\n",
            "Epoch [386/2000], Step [1/3], Loss: 507916.9375\n",
            "Epoch [387/2000], Step [1/3], Loss: 509554.1250\n",
            "Epoch [388/2000], Step [1/3], Loss: 510821.5938\n",
            "Epoch [389/2000], Step [1/3], Loss: 507387.6875\n",
            "Epoch [390/2000], Step [1/3], Loss: 507096.0625\n",
            "Epoch [391/2000], Step [1/3], Loss: 509450.6250\n",
            "Epoch [392/2000], Step [1/3], Loss: 509405.4062\n",
            "Epoch [393/2000], Step [1/3], Loss: 509973.8750\n",
            "Epoch [394/2000], Step [1/3], Loss: 506461.1250\n",
            "Epoch [395/2000], Step [1/3], Loss: 510144.1875\n",
            "Epoch [396/2000], Step [1/3], Loss: 510140.9688\n",
            "Epoch [397/2000], Step [1/3], Loss: 509894.0000\n",
            "Epoch [398/2000], Step [1/3], Loss: 508225.9688\n",
            "Epoch [399/2000], Step [1/3], Loss: 507367.4375\n",
            "Epoch [400/2000], Step [1/3], Loss: 507450.0312\n",
            "Epoch [401/2000], Step [1/3], Loss: 508974.8438\n",
            "Epoch [402/2000], Step [1/3], Loss: 512310.6250\n",
            "Epoch [403/2000], Step [1/3], Loss: 508720.3750\n",
            "Epoch [404/2000], Step [1/3], Loss: 508064.6250\n",
            "Epoch [405/2000], Step [1/3], Loss: 509067.6875\n",
            "Epoch [406/2000], Step [1/3], Loss: 505462.5000\n",
            "Epoch [407/2000], Step [1/3], Loss: 508461.0312\n",
            "Epoch [408/2000], Step [1/3], Loss: 511646.7500\n",
            "Epoch [409/2000], Step [1/3], Loss: 509407.6875\n",
            "Epoch [410/2000], Step [1/3], Loss: 507983.8125\n",
            "Epoch [411/2000], Step [1/3], Loss: 510644.3125\n",
            "Epoch [412/2000], Step [1/3], Loss: 508273.5000\n",
            "Epoch [413/2000], Step [1/3], Loss: 508303.0938\n",
            "Epoch [414/2000], Step [1/3], Loss: 507910.0000\n",
            "Epoch [415/2000], Step [1/3], Loss: 506789.1250\n",
            "Epoch [416/2000], Step [1/3], Loss: 511080.0938\n",
            "Epoch [417/2000], Step [1/3], Loss: 508509.3125\n",
            "Epoch [418/2000], Step [1/3], Loss: 509469.8438\n",
            "Epoch [419/2000], Step [1/3], Loss: 508422.3750\n",
            "Epoch [420/2000], Step [1/3], Loss: 508787.5625\n",
            "Epoch [421/2000], Step [1/3], Loss: 508795.9062\n",
            "Epoch [422/2000], Step [1/3], Loss: 507710.2188\n",
            "Epoch [423/2000], Step [1/3], Loss: 506458.6562\n",
            "Epoch [424/2000], Step [1/3], Loss: 509361.2812\n",
            "Epoch [425/2000], Step [1/3], Loss: 508293.4688\n",
            "Epoch [426/2000], Step [1/3], Loss: 509056.5625\n",
            "Epoch [427/2000], Step [1/3], Loss: 508945.6250\n",
            "Epoch [428/2000], Step [1/3], Loss: 509005.3125\n",
            "Epoch [429/2000], Step [1/3], Loss: 510409.0938\n",
            "Epoch [430/2000], Step [1/3], Loss: 510160.5312\n",
            "Epoch [431/2000], Step [1/3], Loss: 508529.7188\n",
            "Epoch [432/2000], Step [1/3], Loss: 509052.5000\n",
            "Epoch [433/2000], Step [1/3], Loss: 508406.2500\n",
            "Epoch [434/2000], Step [1/3], Loss: 509434.0312\n",
            "Epoch [435/2000], Step [1/3], Loss: 509023.1562\n",
            "Epoch [436/2000], Step [1/3], Loss: 508570.3125\n",
            "Epoch [437/2000], Step [1/3], Loss: 508231.9375\n",
            "Epoch [438/2000], Step [1/3], Loss: 507918.3750\n",
            "Epoch [439/2000], Step [1/3], Loss: 509792.9062\n",
            "Epoch [440/2000], Step [1/3], Loss: 507447.5625\n",
            "Epoch [441/2000], Step [1/3], Loss: 509152.5625\n",
            "Epoch [442/2000], Step [1/3], Loss: 504410.8125\n",
            "Epoch [443/2000], Step [1/3], Loss: 510234.9062\n",
            "Epoch [444/2000], Step [1/3], Loss: 507976.4375\n",
            "Epoch [445/2000], Step [1/3], Loss: 510432.1562\n",
            "Epoch [446/2000], Step [1/3], Loss: 507144.0000\n",
            "Epoch [447/2000], Step [1/3], Loss: 510645.4688\n",
            "Epoch [448/2000], Step [1/3], Loss: 507759.9688\n",
            "Epoch [449/2000], Step [1/3], Loss: 508109.2812\n",
            "Epoch [450/2000], Step [1/3], Loss: 507125.1875\n",
            "Epoch [451/2000], Step [1/3], Loss: 506684.4688\n",
            "Epoch [452/2000], Step [1/3], Loss: 508347.1562\n",
            "Epoch [453/2000], Step [1/3], Loss: 506960.1562\n",
            "Epoch [454/2000], Step [1/3], Loss: 509501.0938\n",
            "Epoch [455/2000], Step [1/3], Loss: 507108.1250\n",
            "Epoch [456/2000], Step [1/3], Loss: 506590.7500\n",
            "Epoch [457/2000], Step [1/3], Loss: 508604.2500\n",
            "Epoch [458/2000], Step [1/3], Loss: 508894.8438\n",
            "Epoch [459/2000], Step [1/3], Loss: 507605.8125\n",
            "Epoch [460/2000], Step [1/3], Loss: 507334.6875\n",
            "Epoch [461/2000], Step [1/3], Loss: 506746.9375\n",
            "Epoch [462/2000], Step [1/3], Loss: 509045.8125\n",
            "Epoch [463/2000], Step [1/3], Loss: 508770.5312\n",
            "Epoch [464/2000], Step [1/3], Loss: 507323.9375\n",
            "Epoch [465/2000], Step [1/3], Loss: 506204.2812\n",
            "Epoch [466/2000], Step [1/3], Loss: 506637.5938\n",
            "Epoch [467/2000], Step [1/3], Loss: 510074.7188\n",
            "Epoch [468/2000], Step [1/3], Loss: 509909.5625\n",
            "Epoch [469/2000], Step [1/3], Loss: 508650.0938\n",
            "Epoch [470/2000], Step [1/3], Loss: 506383.2188\n",
            "Epoch [471/2000], Step [1/3], Loss: 507760.5312\n",
            "Epoch [472/2000], Step [1/3], Loss: 507026.3438\n",
            "Epoch [473/2000], Step [1/3], Loss: 508264.2188\n",
            "Epoch [474/2000], Step [1/3], Loss: 506896.9688\n",
            "Epoch [475/2000], Step [1/3], Loss: 508262.1562\n",
            "Epoch [476/2000], Step [1/3], Loss: 509804.8438\n",
            "Epoch [477/2000], Step [1/3], Loss: 505548.0938\n",
            "Epoch [478/2000], Step [1/3], Loss: 508448.5000\n",
            "Epoch [479/2000], Step [1/3], Loss: 509590.5625\n",
            "Epoch [480/2000], Step [1/3], Loss: 506696.4688\n",
            "Epoch [481/2000], Step [1/3], Loss: 507527.3750\n",
            "Epoch [482/2000], Step [1/3], Loss: 508255.1562\n",
            "Epoch [483/2000], Step [1/3], Loss: 505831.1250\n",
            "Epoch [484/2000], Step [1/3], Loss: 506169.4062\n",
            "Epoch [485/2000], Step [1/3], Loss: 508639.2188\n",
            "Epoch [486/2000], Step [1/3], Loss: 509391.8750\n",
            "Epoch [487/2000], Step [1/3], Loss: 505270.5938\n",
            "Epoch [488/2000], Step [1/3], Loss: 507136.2812\n",
            "Epoch [489/2000], Step [1/3], Loss: 505143.5000\n",
            "Epoch [490/2000], Step [1/3], Loss: 507492.8438\n",
            "Epoch [491/2000], Step [1/3], Loss: 507807.4062\n",
            "Epoch [492/2000], Step [1/3], Loss: 505196.7188\n",
            "Epoch [493/2000], Step [1/3], Loss: 508671.4375\n",
            "Epoch [494/2000], Step [1/3], Loss: 509000.5000\n",
            "Epoch [495/2000], Step [1/3], Loss: 506722.6250\n",
            "Epoch [496/2000], Step [1/3], Loss: 506306.8125\n",
            "Epoch [497/2000], Step [1/3], Loss: 504890.7812\n",
            "Epoch [498/2000], Step [1/3], Loss: 505199.1250\n",
            "Epoch [499/2000], Step [1/3], Loss: 508960.8438\n",
            "Epoch [500/2000], Step [1/3], Loss: 507386.6875\n",
            "Epoch [501/2000], Step [1/3], Loss: 506778.2500\n",
            "Epoch [502/2000], Step [1/3], Loss: 507475.7500\n",
            "Epoch [503/2000], Step [1/3], Loss: 507948.1250\n",
            "Epoch [504/2000], Step [1/3], Loss: 507577.1562\n",
            "Epoch [505/2000], Step [1/3], Loss: 508011.7812\n",
            "Epoch [506/2000], Step [1/3], Loss: 506469.4062\n",
            "Epoch [507/2000], Step [1/3], Loss: 505652.1562\n",
            "Epoch [508/2000], Step [1/3], Loss: 507508.7812\n",
            "Epoch [509/2000], Step [1/3], Loss: 506040.6250\n",
            "Epoch [510/2000], Step [1/3], Loss: 506088.7188\n",
            "Epoch [511/2000], Step [1/3], Loss: 507271.3125\n",
            "Epoch [512/2000], Step [1/3], Loss: 506066.3438\n",
            "Epoch [513/2000], Step [1/3], Loss: 507580.3750\n",
            "Epoch [514/2000], Step [1/3], Loss: 506933.7812\n",
            "Epoch [515/2000], Step [1/3], Loss: 505238.1875\n",
            "Epoch [516/2000], Step [1/3], Loss: 505057.1562\n",
            "Epoch [517/2000], Step [1/3], Loss: 506180.3125\n",
            "Epoch [518/2000], Step [1/3], Loss: 506257.6250\n",
            "Epoch [519/2000], Step [1/3], Loss: 505363.3125\n",
            "Epoch [520/2000], Step [1/3], Loss: 507535.8125\n",
            "Epoch [521/2000], Step [1/3], Loss: 505434.2812\n",
            "Epoch [522/2000], Step [1/3], Loss: 507079.5938\n",
            "Epoch [523/2000], Step [1/3], Loss: 507422.8438\n",
            "Epoch [524/2000], Step [1/3], Loss: 507476.0000\n",
            "Epoch [525/2000], Step [1/3], Loss: 507363.8438\n",
            "Epoch [526/2000], Step [1/3], Loss: 507013.0625\n",
            "Epoch [527/2000], Step [1/3], Loss: 504719.2500\n",
            "Epoch [528/2000], Step [1/3], Loss: 507040.8750\n",
            "Epoch [529/2000], Step [1/3], Loss: 506063.8750\n",
            "Epoch [530/2000], Step [1/3], Loss: 505975.6562\n",
            "Epoch [531/2000], Step [1/3], Loss: 504174.5000\n",
            "Epoch [532/2000], Step [1/3], Loss: 508077.1875\n",
            "Epoch [533/2000], Step [1/3], Loss: 504768.0625\n",
            "Epoch [534/2000], Step [1/3], Loss: 507475.9375\n",
            "Epoch [535/2000], Step [1/3], Loss: 506423.2500\n",
            "Epoch [536/2000], Step [1/3], Loss: 508296.9688\n",
            "Epoch [537/2000], Step [1/3], Loss: 508084.0312\n",
            "Epoch [538/2000], Step [1/3], Loss: 506328.6875\n",
            "Epoch [539/2000], Step [1/3], Loss: 503668.3750\n",
            "Epoch [540/2000], Step [1/3], Loss: 508581.3125\n",
            "Epoch [541/2000], Step [1/3], Loss: 507076.1562\n",
            "Epoch [542/2000], Step [1/3], Loss: 506994.1875\n",
            "Epoch [543/2000], Step [1/3], Loss: 506075.3125\n",
            "Epoch [544/2000], Step [1/3], Loss: 506921.6250\n",
            "Epoch [545/2000], Step [1/3], Loss: 509205.4375\n",
            "Epoch [546/2000], Step [1/3], Loss: 505622.4375\n",
            "Epoch [547/2000], Step [1/3], Loss: 504939.4062\n",
            "Epoch [548/2000], Step [1/3], Loss: 506613.6562\n",
            "Epoch [549/2000], Step [1/3], Loss: 507252.5625\n",
            "Epoch [550/2000], Step [1/3], Loss: 509282.5312\n",
            "Epoch [551/2000], Step [1/3], Loss: 504304.4375\n",
            "Epoch [552/2000], Step [1/3], Loss: 506377.5625\n",
            "Epoch [553/2000], Step [1/3], Loss: 505688.5312\n",
            "Epoch [554/2000], Step [1/3], Loss: 505954.1562\n",
            "Epoch [555/2000], Step [1/3], Loss: 508499.7500\n",
            "Epoch [556/2000], Step [1/3], Loss: 507789.3125\n",
            "Epoch [557/2000], Step [1/3], Loss: 505748.1250\n",
            "Epoch [558/2000], Step [1/3], Loss: 507024.8125\n",
            "Epoch [559/2000], Step [1/3], Loss: 507443.4688\n",
            "Epoch [560/2000], Step [1/3], Loss: 505146.4375\n",
            "Epoch [561/2000], Step [1/3], Loss: 506309.7812\n",
            "Epoch [562/2000], Step [1/3], Loss: 506147.9062\n",
            "Epoch [563/2000], Step [1/3], Loss: 508581.8125\n",
            "Epoch [564/2000], Step [1/3], Loss: 503561.1875\n",
            "Epoch [565/2000], Step [1/3], Loss: 506236.7500\n",
            "Epoch [566/2000], Step [1/3], Loss: 506094.8125\n",
            "Epoch [567/2000], Step [1/3], Loss: 505062.4062\n",
            "Epoch [568/2000], Step [1/3], Loss: 505934.5938\n",
            "Epoch [569/2000], Step [1/3], Loss: 505393.2500\n",
            "Epoch [570/2000], Step [1/3], Loss: 505078.4062\n",
            "Epoch [571/2000], Step [1/3], Loss: 506905.1875\n",
            "Epoch [572/2000], Step [1/3], Loss: 504963.2812\n",
            "Epoch [573/2000], Step [1/3], Loss: 506719.4062\n",
            "Epoch [574/2000], Step [1/3], Loss: 506846.9062\n",
            "Epoch [575/2000], Step [1/3], Loss: 506034.3125\n",
            "Epoch [576/2000], Step [1/3], Loss: 507978.7188\n",
            "Epoch [577/2000], Step [1/3], Loss: 507869.7812\n",
            "Epoch [578/2000], Step [1/3], Loss: 504453.4688\n",
            "Epoch [579/2000], Step [1/3], Loss: 509662.6562\n",
            "Epoch [580/2000], Step [1/3], Loss: 508526.7812\n",
            "Epoch [581/2000], Step [1/3], Loss: 507915.8438\n",
            "Epoch [582/2000], Step [1/3], Loss: 504747.8750\n",
            "Epoch [583/2000], Step [1/3], Loss: 505879.4375\n",
            "Epoch [584/2000], Step [1/3], Loss: 506792.6250\n",
            "Epoch [585/2000], Step [1/3], Loss: 504294.9688\n",
            "Epoch [586/2000], Step [1/3], Loss: 506188.5312\n",
            "Epoch [587/2000], Step [1/3], Loss: 505026.0000\n",
            "Epoch [588/2000], Step [1/3], Loss: 503190.0938\n",
            "Epoch [589/2000], Step [1/3], Loss: 508503.2812\n",
            "Epoch [590/2000], Step [1/3], Loss: 504233.9688\n",
            "Epoch [591/2000], Step [1/3], Loss: 508366.4688\n",
            "Epoch [592/2000], Step [1/3], Loss: 504191.4375\n",
            "Epoch [593/2000], Step [1/3], Loss: 504225.9688\n",
            "Epoch [594/2000], Step [1/3], Loss: 506964.6562\n",
            "Epoch [595/2000], Step [1/3], Loss: 506091.8438\n",
            "Epoch [596/2000], Step [1/3], Loss: 504512.0000\n",
            "Epoch [597/2000], Step [1/3], Loss: 502889.3125\n",
            "Epoch [598/2000], Step [1/3], Loss: 507223.8438\n",
            "Epoch [599/2000], Step [1/3], Loss: 505725.0938\n",
            "Epoch [600/2000], Step [1/3], Loss: 503219.5625\n",
            "Epoch [601/2000], Step [1/3], Loss: 505717.2812\n",
            "Epoch [602/2000], Step [1/3], Loss: 505285.9688\n",
            "Epoch [603/2000], Step [1/3], Loss: 504425.6875\n",
            "Epoch [604/2000], Step [1/3], Loss: 508362.1562\n",
            "Epoch [605/2000], Step [1/3], Loss: 504837.5625\n",
            "Epoch [606/2000], Step [1/3], Loss: 506113.6875\n",
            "Epoch [607/2000], Step [1/3], Loss: 504795.2500\n",
            "Epoch [608/2000], Step [1/3], Loss: 504866.4375\n",
            "Epoch [609/2000], Step [1/3], Loss: 505207.2500\n",
            "Epoch [610/2000], Step [1/3], Loss: 506360.7812\n",
            "Epoch [611/2000], Step [1/3], Loss: 506467.9688\n",
            "Epoch [612/2000], Step [1/3], Loss: 503338.7500\n",
            "Epoch [613/2000], Step [1/3], Loss: 507107.8750\n",
            "Epoch [614/2000], Step [1/3], Loss: 505991.6875\n",
            "Epoch [615/2000], Step [1/3], Loss: 507167.7188\n",
            "Epoch [616/2000], Step [1/3], Loss: 504961.3125\n",
            "Epoch [617/2000], Step [1/3], Loss: 506720.8750\n",
            "Epoch [618/2000], Step [1/3], Loss: 506370.7500\n",
            "Epoch [619/2000], Step [1/3], Loss: 504294.8438\n",
            "Epoch [620/2000], Step [1/3], Loss: 505875.9062\n",
            "Epoch [621/2000], Step [1/3], Loss: 504709.3438\n",
            "Epoch [622/2000], Step [1/3], Loss: 505009.8438\n",
            "Epoch [623/2000], Step [1/3], Loss: 504633.3750\n",
            "Epoch [624/2000], Step [1/3], Loss: 505887.0938\n",
            "Epoch [625/2000], Step [1/3], Loss: 504685.2188\n",
            "Epoch [626/2000], Step [1/3], Loss: 505615.6562\n",
            "Epoch [627/2000], Step [1/3], Loss: 503556.7188\n",
            "Epoch [628/2000], Step [1/3], Loss: 507060.8750\n",
            "Epoch [629/2000], Step [1/3], Loss: 504238.5938\n",
            "Epoch [630/2000], Step [1/3], Loss: 505330.2812\n",
            "Epoch [631/2000], Step [1/3], Loss: 506760.8750\n",
            "Epoch [632/2000], Step [1/3], Loss: 506774.0000\n",
            "Epoch [633/2000], Step [1/3], Loss: 506433.6875\n",
            "Epoch [634/2000], Step [1/3], Loss: 504364.6562\n",
            "Epoch [635/2000], Step [1/3], Loss: 505785.2188\n",
            "Epoch [636/2000], Step [1/3], Loss: 508593.9062\n",
            "Epoch [637/2000], Step [1/3], Loss: 504943.7500\n",
            "Epoch [638/2000], Step [1/3], Loss: 504581.7500\n",
            "Epoch [639/2000], Step [1/3], Loss: 505606.6875\n",
            "Epoch [640/2000], Step [1/3], Loss: 504849.9062\n",
            "Epoch [641/2000], Step [1/3], Loss: 503464.9062\n",
            "Epoch [642/2000], Step [1/3], Loss: 505031.9375\n",
            "Epoch [643/2000], Step [1/3], Loss: 507085.5312\n",
            "Epoch [644/2000], Step [1/3], Loss: 502432.2188\n",
            "Epoch [645/2000], Step [1/3], Loss: 507092.1562\n",
            "Epoch [646/2000], Step [1/3], Loss: 503281.0625\n",
            "Epoch [647/2000], Step [1/3], Loss: 505851.8125\n",
            "Epoch [648/2000], Step [1/3], Loss: 506340.2812\n",
            "Epoch [649/2000], Step [1/3], Loss: 504745.6250\n",
            "Epoch [650/2000], Step [1/3], Loss: 505735.2812\n",
            "Epoch [651/2000], Step [1/3], Loss: 505603.5938\n",
            "Epoch [652/2000], Step [1/3], Loss: 507420.4688\n",
            "Epoch [653/2000], Step [1/3], Loss: 505268.4062\n",
            "Epoch [654/2000], Step [1/3], Loss: 506306.2812\n",
            "Epoch [655/2000], Step [1/3], Loss: 506220.2500\n",
            "Epoch [656/2000], Step [1/3], Loss: 504699.8125\n",
            "Epoch [657/2000], Step [1/3], Loss: 505574.0312\n",
            "Epoch [658/2000], Step [1/3], Loss: 504914.0312\n",
            "Epoch [659/2000], Step [1/3], Loss: 509700.4375\n",
            "Epoch [660/2000], Step [1/3], Loss: 507519.6562\n",
            "Epoch [661/2000], Step [1/3], Loss: 504411.0625\n",
            "Epoch [662/2000], Step [1/3], Loss: 505317.0000\n",
            "Epoch [663/2000], Step [1/3], Loss: 504993.8750\n",
            "Epoch [664/2000], Step [1/3], Loss: 504380.7812\n",
            "Epoch [665/2000], Step [1/3], Loss: 505998.6875\n",
            "Epoch [666/2000], Step [1/3], Loss: 504406.4062\n",
            "Epoch [667/2000], Step [1/3], Loss: 508590.0312\n",
            "Epoch [668/2000], Step [1/3], Loss: 503211.3750\n",
            "Epoch [669/2000], Step [1/3], Loss: 509086.0000\n",
            "Epoch [670/2000], Step [1/3], Loss: 504870.3438\n",
            "Epoch [671/2000], Step [1/3], Loss: 506804.8125\n",
            "Epoch [672/2000], Step [1/3], Loss: 506986.9375\n",
            "Epoch [673/2000], Step [1/3], Loss: 504269.3438\n",
            "Epoch [674/2000], Step [1/3], Loss: 507366.1562\n",
            "Epoch [675/2000], Step [1/3], Loss: 503829.3438\n",
            "Epoch [676/2000], Step [1/3], Loss: 503981.9375\n",
            "Epoch [677/2000], Step [1/3], Loss: 503318.5625\n",
            "Epoch [678/2000], Step [1/3], Loss: 505375.2812\n",
            "Epoch [679/2000], Step [1/3], Loss: 505559.1875\n",
            "Epoch [680/2000], Step [1/3], Loss: 505443.6250\n",
            "Epoch [681/2000], Step [1/3], Loss: 505173.5938\n",
            "Epoch [682/2000], Step [1/3], Loss: 505594.7500\n",
            "Epoch [683/2000], Step [1/3], Loss: 504998.1875\n",
            "Epoch [684/2000], Step [1/3], Loss: 504672.8125\n",
            "Epoch [685/2000], Step [1/3], Loss: 503897.3125\n",
            "Epoch [686/2000], Step [1/3], Loss: 499404.7500\n",
            "Epoch [687/2000], Step [1/3], Loss: 503287.6562\n",
            "Epoch [688/2000], Step [1/3], Loss: 505484.8125\n",
            "Epoch [689/2000], Step [1/3], Loss: 503931.6250\n",
            "Epoch [690/2000], Step [1/3], Loss: 506551.0000\n",
            "Epoch [691/2000], Step [1/3], Loss: 504123.1250\n",
            "Epoch [692/2000], Step [1/3], Loss: 503745.8125\n",
            "Epoch [693/2000], Step [1/3], Loss: 504171.9062\n",
            "Epoch [694/2000], Step [1/3], Loss: 506630.4688\n",
            "Epoch [695/2000], Step [1/3], Loss: 504950.4062\n",
            "Epoch [696/2000], Step [1/3], Loss: 503935.8438\n",
            "Epoch [697/2000], Step [1/3], Loss: 506094.4375\n",
            "Epoch [698/2000], Step [1/3], Loss: 504897.5625\n",
            "Epoch [699/2000], Step [1/3], Loss: 505069.7500\n",
            "Epoch [700/2000], Step [1/3], Loss: 504556.7188\n",
            "Epoch [701/2000], Step [1/3], Loss: 505315.2812\n",
            "Epoch [702/2000], Step [1/3], Loss: 502314.0000\n",
            "Epoch [703/2000], Step [1/3], Loss: 503685.5000\n",
            "Epoch [704/2000], Step [1/3], Loss: 505831.4688\n",
            "Epoch [705/2000], Step [1/3], Loss: 504902.0625\n",
            "Epoch [706/2000], Step [1/3], Loss: 503433.8438\n",
            "Epoch [707/2000], Step [1/3], Loss: 504428.5938\n",
            "Epoch [708/2000], Step [1/3], Loss: 504081.2500\n",
            "Epoch [709/2000], Step [1/3], Loss: 503846.9375\n",
            "Epoch [710/2000], Step [1/3], Loss: 505128.1875\n",
            "Epoch [711/2000], Step [1/3], Loss: 503137.1875\n",
            "Epoch [712/2000], Step [1/3], Loss: 504443.2188\n",
            "Epoch [713/2000], Step [1/3], Loss: 504903.6562\n",
            "Epoch [714/2000], Step [1/3], Loss: 504558.9375\n",
            "Epoch [715/2000], Step [1/3], Loss: 505219.6250\n",
            "Epoch [716/2000], Step [1/3], Loss: 504232.8125\n",
            "Epoch [717/2000], Step [1/3], Loss: 500085.1875\n",
            "Epoch [718/2000], Step [1/3], Loss: 506960.0938\n",
            "Epoch [719/2000], Step [1/3], Loss: 503797.3125\n",
            "Epoch [720/2000], Step [1/3], Loss: 503516.4062\n",
            "Epoch [721/2000], Step [1/3], Loss: 504228.9375\n",
            "Epoch [722/2000], Step [1/3], Loss: 503963.3438\n",
            "Epoch [723/2000], Step [1/3], Loss: 502670.8125\n",
            "Epoch [724/2000], Step [1/3], Loss: 501766.7812\n",
            "Epoch [725/2000], Step [1/3], Loss: 505274.5000\n",
            "Epoch [726/2000], Step [1/3], Loss: 505026.1250\n",
            "Epoch [727/2000], Step [1/3], Loss: 505218.8125\n",
            "Epoch [728/2000], Step [1/3], Loss: 504287.5312\n",
            "Epoch [729/2000], Step [1/3], Loss: 506738.5625\n",
            "Epoch [730/2000], Step [1/3], Loss: 506144.1250\n",
            "Epoch [731/2000], Step [1/3], Loss: 503275.3438\n",
            "Epoch [732/2000], Step [1/3], Loss: 502219.2188\n",
            "Epoch [733/2000], Step [1/3], Loss: 505725.5000\n",
            "Epoch [734/2000], Step [1/3], Loss: 503595.5000\n",
            "Epoch [735/2000], Step [1/3], Loss: 503834.1250\n",
            "Epoch [736/2000], Step [1/3], Loss: 505082.7812\n",
            "Epoch [737/2000], Step [1/3], Loss: 503121.9062\n",
            "Epoch [738/2000], Step [1/3], Loss: 503718.1250\n",
            "Epoch [739/2000], Step [1/3], Loss: 502283.9062\n",
            "Epoch [740/2000], Step [1/3], Loss: 506338.0625\n",
            "Epoch [741/2000], Step [1/3], Loss: 505482.9688\n",
            "Epoch [742/2000], Step [1/3], Loss: 505606.3438\n",
            "Epoch [743/2000], Step [1/3], Loss: 504340.6250\n",
            "Epoch [744/2000], Step [1/3], Loss: 504077.9375\n",
            "Epoch [745/2000], Step [1/3], Loss: 504978.3438\n",
            "Epoch [746/2000], Step [1/3], Loss: 503311.2500\n",
            "Epoch [747/2000], Step [1/3], Loss: 506358.5000\n",
            "Epoch [748/2000], Step [1/3], Loss: 507280.5000\n",
            "Epoch [749/2000], Step [1/3], Loss: 504534.7500\n",
            "Epoch [750/2000], Step [1/3], Loss: 505185.9062\n",
            "Epoch [751/2000], Step [1/3], Loss: 505510.0625\n",
            "Epoch [752/2000], Step [1/3], Loss: 504276.8438\n",
            "Epoch [753/2000], Step [1/3], Loss: 504932.5312\n",
            "Epoch [754/2000], Step [1/3], Loss: 503298.7500\n",
            "Epoch [755/2000], Step [1/3], Loss: 505262.9375\n",
            "Epoch [756/2000], Step [1/3], Loss: 504992.2812\n",
            "Epoch [757/2000], Step [1/3], Loss: 503111.0312\n",
            "Epoch [758/2000], Step [1/3], Loss: 505636.0938\n",
            "Epoch [759/2000], Step [1/3], Loss: 502549.8438\n",
            "Epoch [760/2000], Step [1/3], Loss: 504416.0312\n",
            "Epoch [761/2000], Step [1/3], Loss: 504630.1562\n",
            "Epoch [762/2000], Step [1/3], Loss: 504636.0000\n",
            "Epoch [763/2000], Step [1/3], Loss: 503442.2500\n",
            "Epoch [764/2000], Step [1/3], Loss: 504042.0625\n",
            "Epoch [765/2000], Step [1/3], Loss: 504032.9062\n",
            "Epoch [766/2000], Step [1/3], Loss: 506431.6250\n",
            "Epoch [767/2000], Step [1/3], Loss: 504031.5625\n",
            "Epoch [768/2000], Step [1/3], Loss: 503768.3438\n",
            "Epoch [769/2000], Step [1/3], Loss: 505822.6875\n",
            "Epoch [770/2000], Step [1/3], Loss: 501540.0625\n",
            "Epoch [771/2000], Step [1/3], Loss: 505371.0625\n",
            "Epoch [772/2000], Step [1/3], Loss: 504136.4375\n",
            "Epoch [773/2000], Step [1/3], Loss: 504839.7812\n",
            "Epoch [774/2000], Step [1/3], Loss: 504199.0000\n",
            "Epoch [775/2000], Step [1/3], Loss: 504663.9062\n",
            "Epoch [776/2000], Step [1/3], Loss: 503480.1250\n",
            "Epoch [777/2000], Step [1/3], Loss: 506594.2188\n",
            "Epoch [778/2000], Step [1/3], Loss: 504704.9375\n",
            "Epoch [779/2000], Step [1/3], Loss: 503255.8438\n",
            "Epoch [780/2000], Step [1/3], Loss: 503687.8750\n",
            "Epoch [781/2000], Step [1/3], Loss: 503190.1250\n",
            "Epoch [782/2000], Step [1/3], Loss: 505641.5000\n",
            "Epoch [783/2000], Step [1/3], Loss: 503419.8438\n",
            "Epoch [784/2000], Step [1/3], Loss: 505383.8125\n",
            "Epoch [785/2000], Step [1/3], Loss: 502537.4062\n",
            "Epoch [786/2000], Step [1/3], Loss: 504031.8125\n",
            "Epoch [787/2000], Step [1/3], Loss: 503998.3125\n",
            "Epoch [788/2000], Step [1/3], Loss: 503154.1250\n",
            "Epoch [789/2000], Step [1/3], Loss: 504038.7812\n",
            "Epoch [790/2000], Step [1/3], Loss: 504519.9375\n",
            "Epoch [791/2000], Step [1/3], Loss: 503631.7812\n",
            "Epoch [792/2000], Step [1/3], Loss: 505669.5938\n",
            "Epoch [793/2000], Step [1/3], Loss: 505796.0938\n",
            "Epoch [794/2000], Step [1/3], Loss: 503785.5312\n",
            "Epoch [795/2000], Step [1/3], Loss: 503683.4062\n",
            "Epoch [796/2000], Step [1/3], Loss: 502394.0938\n",
            "Epoch [797/2000], Step [1/3], Loss: 504465.5000\n",
            "Epoch [798/2000], Step [1/3], Loss: 503349.7188\n",
            "Epoch [799/2000], Step [1/3], Loss: 503685.9375\n",
            "Epoch [800/2000], Step [1/3], Loss: 502305.2188\n",
            "Epoch [801/2000], Step [1/3], Loss: 502426.4688\n",
            "Epoch [802/2000], Step [1/3], Loss: 501285.7188\n",
            "Epoch [803/2000], Step [1/3], Loss: 504298.1875\n",
            "Epoch [804/2000], Step [1/3], Loss: 505445.2500\n",
            "Epoch [805/2000], Step [1/3], Loss: 504156.5000\n",
            "Epoch [806/2000], Step [1/3], Loss: 501669.6562\n",
            "Epoch [807/2000], Step [1/3], Loss: 503490.3438\n",
            "Epoch [808/2000], Step [1/3], Loss: 504765.4688\n",
            "Epoch [809/2000], Step [1/3], Loss: 505523.5312\n",
            "Epoch [810/2000], Step [1/3], Loss: 507114.3750\n",
            "Epoch [811/2000], Step [1/3], Loss: 505908.9688\n",
            "Epoch [812/2000], Step [1/3], Loss: 499874.8750\n",
            "Epoch [813/2000], Step [1/3], Loss: 503757.5000\n",
            "Epoch [814/2000], Step [1/3], Loss: 503960.2500\n",
            "Epoch [815/2000], Step [1/3], Loss: 500409.3125\n",
            "Epoch [816/2000], Step [1/3], Loss: 504440.2812\n",
            "Epoch [817/2000], Step [1/3], Loss: 505976.7812\n",
            "Epoch [818/2000], Step [1/3], Loss: 506484.1875\n",
            "Epoch [819/2000], Step [1/3], Loss: 505534.8438\n",
            "Epoch [820/2000], Step [1/3], Loss: 502846.0312\n",
            "Epoch [821/2000], Step [1/3], Loss: 503011.1562\n",
            "Epoch [822/2000], Step [1/3], Loss: 502177.9062\n",
            "Epoch [823/2000], Step [1/3], Loss: 504167.4688\n",
            "Epoch [824/2000], Step [1/3], Loss: 506162.2500\n",
            "Epoch [825/2000], Step [1/3], Loss: 505481.2188\n",
            "Epoch [826/2000], Step [1/3], Loss: 505422.3438\n",
            "Epoch [827/2000], Step [1/3], Loss: 503932.9062\n",
            "Epoch [828/2000], Step [1/3], Loss: 502513.9375\n",
            "Epoch [829/2000], Step [1/3], Loss: 503003.7500\n",
            "Epoch [830/2000], Step [1/3], Loss: 502882.9688\n",
            "Epoch [831/2000], Step [1/3], Loss: 505023.5625\n",
            "Epoch [832/2000], Step [1/3], Loss: 504703.1875\n",
            "Epoch [833/2000], Step [1/3], Loss: 505228.6250\n",
            "Epoch [834/2000], Step [1/3], Loss: 500273.9062\n",
            "Epoch [835/2000], Step [1/3], Loss: 502492.9375\n",
            "Epoch [836/2000], Step [1/3], Loss: 505046.2500\n",
            "Epoch [837/2000], Step [1/3], Loss: 506017.9062\n",
            "Epoch [838/2000], Step [1/3], Loss: 502787.7500\n",
            "Epoch [839/2000], Step [1/3], Loss: 502412.1250\n",
            "Epoch [840/2000], Step [1/3], Loss: 503237.5000\n",
            "Epoch [841/2000], Step [1/3], Loss: 500813.5312\n",
            "Epoch [842/2000], Step [1/3], Loss: 505872.8750\n",
            "Epoch [843/2000], Step [1/3], Loss: 504735.7500\n",
            "Epoch [844/2000], Step [1/3], Loss: 504486.7500\n",
            "Epoch [845/2000], Step [1/3], Loss: 502502.9375\n",
            "Epoch [846/2000], Step [1/3], Loss: 505863.1875\n",
            "Epoch [847/2000], Step [1/3], Loss: 501878.4688\n",
            "Epoch [848/2000], Step [1/3], Loss: 504762.7188\n",
            "Epoch [849/2000], Step [1/3], Loss: 503939.1562\n",
            "Epoch [850/2000], Step [1/3], Loss: 504163.4062\n",
            "Epoch [851/2000], Step [1/3], Loss: 502230.7500\n",
            "Epoch [852/2000], Step [1/3], Loss: 502598.6250\n",
            "Epoch [853/2000], Step [1/3], Loss: 505384.8438\n",
            "Epoch [854/2000], Step [1/3], Loss: 501998.1250\n",
            "Epoch [855/2000], Step [1/3], Loss: 500694.3750\n",
            "Epoch [856/2000], Step [1/3], Loss: 504175.1562\n",
            "Epoch [857/2000], Step [1/3], Loss: 502396.6250\n",
            "Epoch [858/2000], Step [1/3], Loss: 503248.2188\n",
            "Epoch [859/2000], Step [1/3], Loss: 504486.8438\n",
            "Epoch [860/2000], Step [1/3], Loss: 506383.5312\n",
            "Epoch [861/2000], Step [1/3], Loss: 502586.2188\n",
            "Epoch [862/2000], Step [1/3], Loss: 503434.2812\n",
            "Epoch [863/2000], Step [1/3], Loss: 503258.7500\n",
            "Epoch [864/2000], Step [1/3], Loss: 502977.5938\n",
            "Epoch [865/2000], Step [1/3], Loss: 501531.5938\n",
            "Epoch [866/2000], Step [1/3], Loss: 504341.5625\n",
            "Epoch [867/2000], Step [1/3], Loss: 504705.0938\n",
            "Epoch [868/2000], Step [1/3], Loss: 503722.0938\n",
            "Epoch [869/2000], Step [1/3], Loss: 502263.5000\n",
            "Epoch [870/2000], Step [1/3], Loss: 503923.5312\n",
            "Epoch [871/2000], Step [1/3], Loss: 502254.0938\n",
            "Epoch [872/2000], Step [1/3], Loss: 503894.7812\n",
            "Epoch [873/2000], Step [1/3], Loss: 504756.5938\n",
            "Epoch [874/2000], Step [1/3], Loss: 503399.7500\n",
            "Epoch [875/2000], Step [1/3], Loss: 508011.4688\n",
            "Epoch [876/2000], Step [1/3], Loss: 503890.3750\n",
            "Epoch [877/2000], Step [1/3], Loss: 505298.5938\n",
            "Epoch [878/2000], Step [1/3], Loss: 505284.9062\n",
            "Epoch [879/2000], Step [1/3], Loss: 504535.6562\n",
            "Epoch [880/2000], Step [1/3], Loss: 500474.3750\n",
            "Epoch [881/2000], Step [1/3], Loss: 501890.7500\n",
            "Epoch [882/2000], Step [1/3], Loss: 503257.7812\n",
            "Epoch [883/2000], Step [1/3], Loss: 504035.8438\n",
            "Epoch [884/2000], Step [1/3], Loss: 504380.3125\n",
            "Epoch [885/2000], Step [1/3], Loss: 504306.4062\n",
            "Epoch [886/2000], Step [1/3], Loss: 501879.1562\n",
            "Epoch [887/2000], Step [1/3], Loss: 503169.7500\n",
            "Epoch [888/2000], Step [1/3], Loss: 502336.2500\n",
            "Epoch [889/2000], Step [1/3], Loss: 502249.7500\n",
            "Epoch [890/2000], Step [1/3], Loss: 503870.6875\n",
            "Epoch [891/2000], Step [1/3], Loss: 502751.0312\n",
            "Epoch [892/2000], Step [1/3], Loss: 503932.2188\n",
            "Epoch [893/2000], Step [1/3], Loss: 506408.0625\n",
            "Epoch [894/2000], Step [1/3], Loss: 500920.0000\n",
            "Epoch [895/2000], Step [1/3], Loss: 501025.6250\n",
            "Epoch [896/2000], Step [1/3], Loss: 504438.4375\n",
            "Epoch [897/2000], Step [1/3], Loss: 502518.8750\n",
            "Epoch [898/2000], Step [1/3], Loss: 505074.0625\n",
            "Epoch [899/2000], Step [1/3], Loss: 501601.6875\n",
            "Epoch [900/2000], Step [1/3], Loss: 506494.8750\n",
            "Epoch [901/2000], Step [1/3], Loss: 504365.3438\n",
            "Epoch [902/2000], Step [1/3], Loss: 503869.0000\n",
            "Epoch [903/2000], Step [1/3], Loss: 501339.8125\n",
            "Epoch [904/2000], Step [1/3], Loss: 505368.3125\n",
            "Epoch [905/2000], Step [1/3], Loss: 502259.5625\n",
            "Epoch [906/2000], Step [1/3], Loss: 502256.2500\n",
            "Epoch [907/2000], Step [1/3], Loss: 502985.4062\n",
            "Epoch [908/2000], Step [1/3], Loss: 503101.6875\n",
            "Epoch [909/2000], Step [1/3], Loss: 501943.9375\n",
            "Epoch [910/2000], Step [1/3], Loss: 501213.6250\n",
            "Epoch [911/2000], Step [1/3], Loss: 504453.5312\n",
            "Epoch [912/2000], Step [1/3], Loss: 501451.5938\n",
            "Epoch [913/2000], Step [1/3], Loss: 504159.4062\n",
            "Epoch [914/2000], Step [1/3], Loss: 502220.1562\n",
            "Epoch [915/2000], Step [1/3], Loss: 501935.5312\n",
            "Epoch [916/2000], Step [1/3], Loss: 503218.8750\n",
            "Epoch [917/2000], Step [1/3], Loss: 501295.4688\n",
            "Epoch [918/2000], Step [1/3], Loss: 503355.3750\n",
            "Epoch [919/2000], Step [1/3], Loss: 504503.6250\n",
            "Epoch [920/2000], Step [1/3], Loss: 503339.5312\n",
            "Epoch [921/2000], Step [1/3], Loss: 500127.6875\n",
            "Epoch [922/2000], Step [1/3], Loss: 505116.6875\n",
            "Epoch [923/2000], Step [1/3], Loss: 501172.7188\n",
            "Epoch [924/2000], Step [1/3], Loss: 502433.7812\n",
            "Epoch [925/2000], Step [1/3], Loss: 504957.5312\n",
            "Epoch [926/2000], Step [1/3], Loss: 505622.1250\n",
            "Epoch [927/2000], Step [1/3], Loss: 503790.9375\n",
            "Epoch [928/2000], Step [1/3], Loss: 504454.7812\n",
            "Epoch [929/2000], Step [1/3], Loss: 503934.7500\n",
            "Epoch [930/2000], Step [1/3], Loss: 504036.6875\n",
            "Epoch [931/2000], Step [1/3], Loss: 502134.6562\n",
            "Epoch [932/2000], Step [1/3], Loss: 502744.8750\n",
            "Epoch [933/2000], Step [1/3], Loss: 504954.6562\n",
            "Epoch [934/2000], Step [1/3], Loss: 503110.2500\n",
            "Epoch [935/2000], Step [1/3], Loss: 500557.2500\n",
            "Epoch [936/2000], Step [1/3], Loss: 503092.6250\n",
            "Epoch [937/2000], Step [1/3], Loss: 501703.6875\n",
            "Epoch [938/2000], Step [1/3], Loss: 506032.1562\n",
            "Epoch [939/2000], Step [1/3], Loss: 502351.5938\n",
            "Epoch [940/2000], Step [1/3], Loss: 503288.5312\n",
            "Epoch [941/2000], Step [1/3], Loss: 504860.0938\n",
            "Epoch [942/2000], Step [1/3], Loss: 502129.7188\n",
            "Epoch [943/2000], Step [1/3], Loss: 500732.9062\n",
            "Epoch [944/2000], Step [1/3], Loss: 501691.9062\n",
            "Epoch [945/2000], Step [1/3], Loss: 502121.7812\n",
            "Epoch [946/2000], Step [1/3], Loss: 503741.6562\n",
            "Epoch [947/2000], Step [1/3], Loss: 502405.5625\n",
            "Epoch [948/2000], Step [1/3], Loss: 502143.5312\n",
            "Epoch [949/2000], Step [1/3], Loss: 502695.1875\n",
            "Epoch [950/2000], Step [1/3], Loss: 503747.5938\n",
            "Epoch [951/2000], Step [1/3], Loss: 503591.7500\n",
            "Epoch [952/2000], Step [1/3], Loss: 500428.6562\n",
            "Epoch [953/2000], Step [1/3], Loss: 500429.3438\n",
            "Epoch [954/2000], Step [1/3], Loss: 502664.7188\n",
            "Epoch [955/2000], Step [1/3], Loss: 503605.6250\n",
            "Epoch [956/2000], Step [1/3], Loss: 502039.7500\n",
            "Epoch [957/2000], Step [1/3], Loss: 502572.8438\n",
            "Epoch [958/2000], Step [1/3], Loss: 501804.1250\n",
            "Epoch [959/2000], Step [1/3], Loss: 504792.2188\n",
            "Epoch [960/2000], Step [1/3], Loss: 502217.7188\n",
            "Epoch [961/2000], Step [1/3], Loss: 502934.3750\n",
            "Epoch [962/2000], Step [1/3], Loss: 502139.3125\n",
            "Epoch [963/2000], Step [1/3], Loss: 501748.8125\n",
            "Epoch [964/2000], Step [1/3], Loss: 502449.8438\n",
            "Epoch [965/2000], Step [1/3], Loss: 503073.5312\n",
            "Epoch [966/2000], Step [1/3], Loss: 505835.3438\n",
            "Epoch [967/2000], Step [1/3], Loss: 503132.0312\n",
            "Epoch [968/2000], Step [1/3], Loss: 503747.1562\n",
            "Epoch [969/2000], Step [1/3], Loss: 506975.0938\n",
            "Epoch [970/2000], Step [1/3], Loss: 502972.9062\n",
            "Epoch [971/2000], Step [1/3], Loss: 503592.9062\n",
            "Epoch [972/2000], Step [1/3], Loss: 501998.7500\n",
            "Epoch [973/2000], Step [1/3], Loss: 501059.3125\n",
            "Epoch [974/2000], Step [1/3], Loss: 500649.0938\n",
            "Epoch [975/2000], Step [1/3], Loss: 501274.5312\n",
            "Epoch [976/2000], Step [1/3], Loss: 504292.5000\n",
            "Epoch [977/2000], Step [1/3], Loss: 501941.5938\n",
            "Epoch [978/2000], Step [1/3], Loss: 504213.3438\n",
            "Epoch [979/2000], Step [1/3], Loss: 500818.5938\n",
            "Epoch [980/2000], Step [1/3], Loss: 502957.7500\n",
            "Epoch [981/2000], Step [1/3], Loss: 503144.9375\n",
            "Epoch [982/2000], Step [1/3], Loss: 505576.2188\n",
            "Epoch [983/2000], Step [1/3], Loss: 500835.2812\n",
            "Epoch [984/2000], Step [1/3], Loss: 502041.8750\n",
            "Epoch [985/2000], Step [1/3], Loss: 502002.7188\n",
            "Epoch [986/2000], Step [1/3], Loss: 505029.7188\n",
            "Epoch [987/2000], Step [1/3], Loss: 504984.1562\n",
            "Epoch [988/2000], Step [1/3], Loss: 503026.8438\n",
            "Epoch [989/2000], Step [1/3], Loss: 503952.1250\n",
            "Epoch [990/2000], Step [1/3], Loss: 500969.3750\n",
            "Epoch [991/2000], Step [1/3], Loss: 502095.5625\n",
            "Epoch [992/2000], Step [1/3], Loss: 502327.7500\n",
            "Epoch [993/2000], Step [1/3], Loss: 503921.7500\n",
            "Epoch [994/2000], Step [1/3], Loss: 503609.5625\n",
            "Epoch [995/2000], Step [1/3], Loss: 502485.1250\n",
            "Epoch [996/2000], Step [1/3], Loss: 503439.5312\n",
            "Epoch [997/2000], Step [1/3], Loss: 505114.5312\n",
            "Epoch [998/2000], Step [1/3], Loss: 501553.9062\n",
            "Epoch [999/2000], Step [1/3], Loss: 499769.5938\n",
            "Epoch [1000/2000], Step [1/3], Loss: 503632.4062\n",
            "Epoch [1001/2000], Step [1/3], Loss: 500491.3125\n",
            "Epoch [1002/2000], Step [1/3], Loss: 503401.9375\n",
            "Epoch [1003/2000], Step [1/3], Loss: 502895.8750\n",
            "Epoch [1004/2000], Step [1/3], Loss: 502504.9375\n",
            "Epoch [1005/2000], Step [1/3], Loss: 500597.6562\n",
            "Epoch [1006/2000], Step [1/3], Loss: 500924.1562\n",
            "Epoch [1007/2000], Step [1/3], Loss: 502946.2812\n",
            "Epoch [1008/2000], Step [1/3], Loss: 501821.6875\n",
            "Epoch [1009/2000], Step [1/3], Loss: 502663.9375\n",
            "Epoch [1010/2000], Step [1/3], Loss: 501777.0312\n",
            "Epoch [1011/2000], Step [1/3], Loss: 504101.2188\n",
            "Epoch [1012/2000], Step [1/3], Loss: 501795.5312\n",
            "Epoch [1013/2000], Step [1/3], Loss: 502370.0625\n",
            "Epoch [1014/2000], Step [1/3], Loss: 501566.2188\n",
            "Epoch [1015/2000], Step [1/3], Loss: 501807.0000\n",
            "Epoch [1016/2000], Step [1/3], Loss: 502089.5938\n",
            "Epoch [1017/2000], Step [1/3], Loss: 501354.2500\n",
            "Epoch [1018/2000], Step [1/3], Loss: 501956.0625\n",
            "Epoch [1019/2000], Step [1/3], Loss: 502138.5938\n",
            "Epoch [1020/2000], Step [1/3], Loss: 500300.5625\n",
            "Epoch [1021/2000], Step [1/3], Loss: 502357.9062\n",
            "Epoch [1022/2000], Step [1/3], Loss: 502703.2500\n",
            "Epoch [1023/2000], Step [1/3], Loss: 502937.7812\n",
            "Epoch [1024/2000], Step [1/3], Loss: 502946.6875\n",
            "Epoch [1025/2000], Step [1/3], Loss: 501742.2188\n",
            "Epoch [1026/2000], Step [1/3], Loss: 501051.5625\n",
            "Epoch [1027/2000], Step [1/3], Loss: 501072.0000\n",
            "Epoch [1028/2000], Step [1/3], Loss: 504817.6250\n",
            "Epoch [1029/2000], Step [1/3], Loss: 500910.0625\n",
            "Epoch [1030/2000], Step [1/3], Loss: 502317.9375\n",
            "Epoch [1031/2000], Step [1/3], Loss: 503249.5625\n",
            "Epoch [1032/2000], Step [1/3], Loss: 501691.5312\n",
            "Epoch [1033/2000], Step [1/3], Loss: 501854.1562\n",
            "Epoch [1034/2000], Step [1/3], Loss: 502272.3750\n",
            "Epoch [1035/2000], Step [1/3], Loss: 501084.7188\n",
            "Epoch [1036/2000], Step [1/3], Loss: 504561.6562\n",
            "Epoch [1037/2000], Step [1/3], Loss: 502136.2812\n",
            "Epoch [1038/2000], Step [1/3], Loss: 502264.6562\n",
            "Epoch [1039/2000], Step [1/3], Loss: 502387.5312\n",
            "Epoch [1040/2000], Step [1/3], Loss: 501301.8438\n",
            "Epoch [1041/2000], Step [1/3], Loss: 503717.6875\n",
            "Epoch [1042/2000], Step [1/3], Loss: 505632.1562\n",
            "Epoch [1043/2000], Step [1/3], Loss: 501820.6875\n",
            "Epoch [1044/2000], Step [1/3], Loss: 504985.2812\n",
            "Epoch [1045/2000], Step [1/3], Loss: 501338.0625\n",
            "Epoch [1046/2000], Step [1/3], Loss: 504250.8125\n",
            "Epoch [1047/2000], Step [1/3], Loss: 502771.7500\n",
            "Epoch [1048/2000], Step [1/3], Loss: 503531.2812\n",
            "Epoch [1049/2000], Step [1/3], Loss: 502938.4375\n",
            "Epoch [1050/2000], Step [1/3], Loss: 501507.4062\n",
            "Epoch [1051/2000], Step [1/3], Loss: 501458.5938\n",
            "Epoch [1052/2000], Step [1/3], Loss: 501025.9688\n",
            "Epoch [1053/2000], Step [1/3], Loss: 502176.4062\n",
            "Epoch [1054/2000], Step [1/3], Loss: 501384.8438\n",
            "Epoch [1055/2000], Step [1/3], Loss: 501666.7500\n",
            "Epoch [1056/2000], Step [1/3], Loss: 503028.5938\n",
            "Epoch [1057/2000], Step [1/3], Loss: 501367.9688\n",
            "Epoch [1058/2000], Step [1/3], Loss: 504275.3750\n",
            "Epoch [1059/2000], Step [1/3], Loss: 503731.0625\n",
            "Epoch [1060/2000], Step [1/3], Loss: 503388.2188\n",
            "Epoch [1061/2000], Step [1/3], Loss: 503802.8750\n",
            "Epoch [1062/2000], Step [1/3], Loss: 502051.0312\n",
            "Epoch [1063/2000], Step [1/3], Loss: 501821.0625\n",
            "Epoch [1064/2000], Step [1/3], Loss: 500652.7812\n",
            "Epoch [1065/2000], Step [1/3], Loss: 502277.6875\n",
            "Epoch [1066/2000], Step [1/3], Loss: 502172.1562\n",
            "Epoch [1067/2000], Step [1/3], Loss: 503838.0312\n",
            "Epoch [1068/2000], Step [1/3], Loss: 502494.8438\n",
            "Epoch [1069/2000], Step [1/3], Loss: 504282.7188\n",
            "Epoch [1070/2000], Step [1/3], Loss: 502790.2188\n",
            "Epoch [1071/2000], Step [1/3], Loss: 503212.0000\n",
            "Epoch [1072/2000], Step [1/3], Loss: 503972.8125\n",
            "Epoch [1073/2000], Step [1/3], Loss: 498616.7500\n",
            "Epoch [1074/2000], Step [1/3], Loss: 502560.9688\n",
            "Epoch [1075/2000], Step [1/3], Loss: 502088.6562\n",
            "Epoch [1076/2000], Step [1/3], Loss: 501735.5938\n",
            "Epoch [1077/2000], Step [1/3], Loss: 503101.3438\n",
            "Epoch [1078/2000], Step [1/3], Loss: 502618.1250\n",
            "Epoch [1079/2000], Step [1/3], Loss: 501158.7500\n",
            "Epoch [1080/2000], Step [1/3], Loss: 501030.6875\n",
            "Epoch [1081/2000], Step [1/3], Loss: 501584.5625\n",
            "Epoch [1082/2000], Step [1/3], Loss: 501867.7500\n",
            "Epoch [1083/2000], Step [1/3], Loss: 500975.2188\n",
            "Epoch [1084/2000], Step [1/3], Loss: 499769.4062\n",
            "Epoch [1085/2000], Step [1/3], Loss: 500547.2500\n",
            "Epoch [1086/2000], Step [1/3], Loss: 501343.5625\n",
            "Epoch [1087/2000], Step [1/3], Loss: 502985.5000\n",
            "Epoch [1088/2000], Step [1/3], Loss: 502296.7188\n",
            "Epoch [1089/2000], Step [1/3], Loss: 505712.0938\n",
            "Epoch [1090/2000], Step [1/3], Loss: 504512.5000\n",
            "Epoch [1091/2000], Step [1/3], Loss: 504585.5938\n",
            "Epoch [1092/2000], Step [1/3], Loss: 503508.6250\n",
            "Epoch [1093/2000], Step [1/3], Loss: 504473.1562\n",
            "Epoch [1094/2000], Step [1/3], Loss: 505067.7812\n",
            "Epoch [1095/2000], Step [1/3], Loss: 502666.6250\n",
            "Epoch [1096/2000], Step [1/3], Loss: 502755.3750\n",
            "Epoch [1097/2000], Step [1/3], Loss: 500688.4062\n",
            "Epoch [1098/2000], Step [1/3], Loss: 500484.3750\n",
            "Epoch [1099/2000], Step [1/3], Loss: 501852.7188\n",
            "Epoch [1100/2000], Step [1/3], Loss: 504207.3125\n",
            "Epoch [1101/2000], Step [1/3], Loss: 501905.2188\n",
            "Epoch [1102/2000], Step [1/3], Loss: 504158.1562\n",
            "Epoch [1103/2000], Step [1/3], Loss: 504564.5938\n",
            "Epoch [1104/2000], Step [1/3], Loss: 501721.4375\n",
            "Epoch [1105/2000], Step [1/3], Loss: 501672.5625\n",
            "Epoch [1106/2000], Step [1/3], Loss: 501339.7188\n",
            "Epoch [1107/2000], Step [1/3], Loss: 502226.2188\n",
            "Epoch [1108/2000], Step [1/3], Loss: 503635.1875\n",
            "Epoch [1109/2000], Step [1/3], Loss: 501277.5312\n",
            "Epoch [1110/2000], Step [1/3], Loss: 500781.0625\n",
            "Epoch [1111/2000], Step [1/3], Loss: 500843.1250\n",
            "Epoch [1112/2000], Step [1/3], Loss: 501713.6875\n",
            "Epoch [1113/2000], Step [1/3], Loss: 502116.1875\n",
            "Epoch [1114/2000], Step [1/3], Loss: 503114.8125\n",
            "Epoch [1115/2000], Step [1/3], Loss: 504903.5625\n",
            "Epoch [1116/2000], Step [1/3], Loss: 500584.9062\n",
            "Epoch [1117/2000], Step [1/3], Loss: 500916.0000\n",
            "Epoch [1118/2000], Step [1/3], Loss: 503065.8125\n",
            "Epoch [1119/2000], Step [1/3], Loss: 502964.9375\n",
            "Epoch [1120/2000], Step [1/3], Loss: 502512.1875\n",
            "Epoch [1121/2000], Step [1/3], Loss: 503479.5938\n",
            "Epoch [1122/2000], Step [1/3], Loss: 502956.4062\n",
            "Epoch [1123/2000], Step [1/3], Loss: 501412.1562\n",
            "Epoch [1124/2000], Step [1/3], Loss: 502347.2812\n",
            "Epoch [1125/2000], Step [1/3], Loss: 501098.8438\n",
            "Epoch [1126/2000], Step [1/3], Loss: 501082.8125\n",
            "Epoch [1127/2000], Step [1/3], Loss: 502894.5625\n",
            "Epoch [1128/2000], Step [1/3], Loss: 502608.6250\n",
            "Epoch [1129/2000], Step [1/3], Loss: 502572.2188\n",
            "Epoch [1130/2000], Step [1/3], Loss: 501753.6250\n",
            "Epoch [1131/2000], Step [1/3], Loss: 502450.5000\n",
            "Epoch [1132/2000], Step [1/3], Loss: 504620.1562\n",
            "Epoch [1133/2000], Step [1/3], Loss: 502699.4688\n",
            "Epoch [1134/2000], Step [1/3], Loss: 500947.2188\n",
            "Epoch [1135/2000], Step [1/3], Loss: 502745.5312\n",
            "Epoch [1136/2000], Step [1/3], Loss: 501778.3438\n",
            "Epoch [1137/2000], Step [1/3], Loss: 502946.7812\n",
            "Epoch [1138/2000], Step [1/3], Loss: 501846.7500\n",
            "Epoch [1139/2000], Step [1/3], Loss: 502672.5625\n",
            "Epoch [1140/2000], Step [1/3], Loss: 499677.4062\n",
            "Epoch [1141/2000], Step [1/3], Loss: 498564.2500\n",
            "Epoch [1142/2000], Step [1/3], Loss: 501321.8125\n",
            "Epoch [1143/2000], Step [1/3], Loss: 504997.9375\n",
            "Epoch [1144/2000], Step [1/3], Loss: 500540.4375\n",
            "Epoch [1145/2000], Step [1/3], Loss: 500212.5000\n",
            "Epoch [1146/2000], Step [1/3], Loss: 502652.1250\n",
            "Epoch [1147/2000], Step [1/3], Loss: 502470.2812\n",
            "Epoch [1148/2000], Step [1/3], Loss: 501726.9375\n",
            "Epoch [1149/2000], Step [1/3], Loss: 501257.7500\n",
            "Epoch [1150/2000], Step [1/3], Loss: 502406.8125\n",
            "Epoch [1151/2000], Step [1/3], Loss: 501657.5312\n",
            "Epoch [1152/2000], Step [1/3], Loss: 502085.3438\n",
            "Epoch [1153/2000], Step [1/3], Loss: 504038.5625\n",
            "Epoch [1154/2000], Step [1/3], Loss: 504766.2812\n",
            "Epoch [1155/2000], Step [1/3], Loss: 504324.8438\n",
            "Epoch [1156/2000], Step [1/3], Loss: 501396.5000\n",
            "Epoch [1157/2000], Step [1/3], Loss: 502362.1562\n",
            "Epoch [1158/2000], Step [1/3], Loss: 501245.2188\n",
            "Epoch [1159/2000], Step [1/3], Loss: 503337.5000\n",
            "Epoch [1160/2000], Step [1/3], Loss: 501908.5625\n",
            "Epoch [1161/2000], Step [1/3], Loss: 500799.3438\n",
            "Epoch [1162/2000], Step [1/3], Loss: 502425.1562\n",
            "Epoch [1163/2000], Step [1/3], Loss: 502690.7188\n",
            "Epoch [1164/2000], Step [1/3], Loss: 500086.8750\n",
            "Epoch [1165/2000], Step [1/3], Loss: 500126.5312\n",
            "Epoch [1166/2000], Step [1/3], Loss: 503871.0000\n",
            "Epoch [1167/2000], Step [1/3], Loss: 501787.7500\n",
            "Epoch [1168/2000], Step [1/3], Loss: 501870.6250\n",
            "Epoch [1169/2000], Step [1/3], Loss: 503009.0938\n",
            "Epoch [1170/2000], Step [1/3], Loss: 501989.9688\n",
            "Epoch [1171/2000], Step [1/3], Loss: 500019.9375\n",
            "Epoch [1172/2000], Step [1/3], Loss: 499647.8125\n",
            "Epoch [1173/2000], Step [1/3], Loss: 502169.0000\n",
            "Epoch [1174/2000], Step [1/3], Loss: 505286.5312\n",
            "Epoch [1175/2000], Step [1/3], Loss: 500615.5625\n",
            "Epoch [1176/2000], Step [1/3], Loss: 502286.7500\n",
            "Epoch [1177/2000], Step [1/3], Loss: 502851.5938\n",
            "Epoch [1178/2000], Step [1/3], Loss: 502936.9375\n",
            "Epoch [1179/2000], Step [1/3], Loss: 502410.8438\n",
            "Epoch [1180/2000], Step [1/3], Loss: 501288.7812\n",
            "Epoch [1181/2000], Step [1/3], Loss: 502177.2812\n",
            "Epoch [1182/2000], Step [1/3], Loss: 502020.5000\n",
            "Epoch [1183/2000], Step [1/3], Loss: 499481.7188\n",
            "Epoch [1184/2000], Step [1/3], Loss: 502736.1250\n",
            "Epoch [1185/2000], Step [1/3], Loss: 504694.5000\n",
            "Epoch [1186/2000], Step [1/3], Loss: 503538.2188\n",
            "Epoch [1187/2000], Step [1/3], Loss: 503957.3438\n",
            "Epoch [1188/2000], Step [1/3], Loss: 499938.3750\n",
            "Epoch [1189/2000], Step [1/3], Loss: 502198.0000\n",
            "Epoch [1190/2000], Step [1/3], Loss: 505300.0000\n",
            "Epoch [1191/2000], Step [1/3], Loss: 503446.1250\n",
            "Epoch [1192/2000], Step [1/3], Loss: 503041.0625\n",
            "Epoch [1193/2000], Step [1/3], Loss: 503587.8438\n",
            "Epoch [1194/2000], Step [1/3], Loss: 501512.0312\n",
            "Epoch [1195/2000], Step [1/3], Loss: 503199.5625\n",
            "Epoch [1196/2000], Step [1/3], Loss: 498677.1250\n",
            "Epoch [1197/2000], Step [1/3], Loss: 502538.4688\n",
            "Epoch [1198/2000], Step [1/3], Loss: 501429.6562\n",
            "Epoch [1199/2000], Step [1/3], Loss: 501548.9375\n",
            "Epoch [1200/2000], Step [1/3], Loss: 503125.9062\n",
            "Epoch [1201/2000], Step [1/3], Loss: 503546.6875\n",
            "Epoch [1202/2000], Step [1/3], Loss: 502820.7188\n",
            "Epoch [1203/2000], Step [1/3], Loss: 504692.2188\n",
            "Epoch [1204/2000], Step [1/3], Loss: 501843.1562\n",
            "Epoch [1205/2000], Step [1/3], Loss: 502465.1250\n",
            "Epoch [1206/2000], Step [1/3], Loss: 504311.5625\n",
            "Epoch [1207/2000], Step [1/3], Loss: 501372.6562\n",
            "Epoch [1208/2000], Step [1/3], Loss: 503539.4688\n",
            "Epoch [1209/2000], Step [1/3], Loss: 501174.2188\n",
            "Epoch [1210/2000], Step [1/3], Loss: 501936.4375\n",
            "Epoch [1211/2000], Step [1/3], Loss: 502073.0312\n",
            "Epoch [1212/2000], Step [1/3], Loss: 503597.0000\n",
            "Epoch [1213/2000], Step [1/3], Loss: 503157.5938\n",
            "Epoch [1214/2000], Step [1/3], Loss: 502141.4062\n",
            "Epoch [1215/2000], Step [1/3], Loss: 500781.7500\n",
            "Epoch [1216/2000], Step [1/3], Loss: 503584.5312\n",
            "Epoch [1217/2000], Step [1/3], Loss: 501977.4375\n",
            "Epoch [1218/2000], Step [1/3], Loss: 501407.0625\n",
            "Epoch [1219/2000], Step [1/3], Loss: 502000.2188\n",
            "Epoch [1220/2000], Step [1/3], Loss: 501400.1875\n",
            "Epoch [1221/2000], Step [1/3], Loss: 503687.3438\n",
            "Epoch [1222/2000], Step [1/3], Loss: 502407.0312\n",
            "Epoch [1223/2000], Step [1/3], Loss: 504044.1875\n",
            "Epoch [1224/2000], Step [1/3], Loss: 501941.3750\n",
            "Epoch [1225/2000], Step [1/3], Loss: 504188.4375\n",
            "Epoch [1226/2000], Step [1/3], Loss: 503292.3125\n",
            "Epoch [1227/2000], Step [1/3], Loss: 503232.5938\n",
            "Epoch [1228/2000], Step [1/3], Loss: 499115.2500\n",
            "Epoch [1229/2000], Step [1/3], Loss: 500671.3125\n",
            "Epoch [1230/2000], Step [1/3], Loss: 500914.7188\n",
            "Epoch [1231/2000], Step [1/3], Loss: 503984.9062\n",
            "Epoch [1232/2000], Step [1/3], Loss: 501413.0312\n",
            "Epoch [1233/2000], Step [1/3], Loss: 502155.7812\n",
            "Epoch [1234/2000], Step [1/3], Loss: 500190.9062\n",
            "Epoch [1235/2000], Step [1/3], Loss: 501329.4062\n",
            "Epoch [1236/2000], Step [1/3], Loss: 499901.2500\n",
            "Epoch [1237/2000], Step [1/3], Loss: 501580.5000\n",
            "Epoch [1238/2000], Step [1/3], Loss: 500137.5625\n",
            "Epoch [1239/2000], Step [1/3], Loss: 503517.5000\n",
            "Epoch [1240/2000], Step [1/3], Loss: 503942.3750\n",
            "Epoch [1241/2000], Step [1/3], Loss: 502275.4375\n",
            "Epoch [1242/2000], Step [1/3], Loss: 499744.4375\n",
            "Epoch [1243/2000], Step [1/3], Loss: 503216.3438\n",
            "Epoch [1244/2000], Step [1/3], Loss: 500683.7812\n",
            "Epoch [1245/2000], Step [1/3], Loss: 503603.4688\n",
            "Epoch [1246/2000], Step [1/3], Loss: 503756.1875\n",
            "Epoch [1247/2000], Step [1/3], Loss: 503250.9375\n",
            "Epoch [1248/2000], Step [1/3], Loss: 499405.9688\n",
            "Epoch [1249/2000], Step [1/3], Loss: 506711.7812\n",
            "Epoch [1250/2000], Step [1/3], Loss: 500973.7812\n",
            "Epoch [1251/2000], Step [1/3], Loss: 500713.7500\n",
            "Epoch [1252/2000], Step [1/3], Loss: 501513.0938\n",
            "Epoch [1253/2000], Step [1/3], Loss: 501216.7812\n",
            "Epoch [1254/2000], Step [1/3], Loss: 502637.6875\n",
            "Epoch [1255/2000], Step [1/3], Loss: 503383.5312\n",
            "Epoch [1256/2000], Step [1/3], Loss: 500700.5312\n",
            "Epoch [1257/2000], Step [1/3], Loss: 502069.5938\n",
            "Epoch [1258/2000], Step [1/3], Loss: 499884.7188\n",
            "Epoch [1259/2000], Step [1/3], Loss: 501244.6875\n",
            "Epoch [1260/2000], Step [1/3], Loss: 502561.7500\n",
            "Epoch [1261/2000], Step [1/3], Loss: 504691.8750\n",
            "Epoch [1262/2000], Step [1/3], Loss: 500728.8125\n",
            "Epoch [1263/2000], Step [1/3], Loss: 503738.0000\n",
            "Epoch [1264/2000], Step [1/3], Loss: 502656.3750\n",
            "Epoch [1265/2000], Step [1/3], Loss: 503605.6875\n",
            "Epoch [1266/2000], Step [1/3], Loss: 499734.1250\n",
            "Epoch [1267/2000], Step [1/3], Loss: 503024.5625\n",
            "Epoch [1268/2000], Step [1/3], Loss: 501821.5312\n",
            "Epoch [1269/2000], Step [1/3], Loss: 500725.2812\n",
            "Epoch [1270/2000], Step [1/3], Loss: 503954.5938\n",
            "Epoch [1271/2000], Step [1/3], Loss: 501409.4688\n",
            "Epoch [1272/2000], Step [1/3], Loss: 502227.7188\n",
            "Epoch [1273/2000], Step [1/3], Loss: 503995.5312\n",
            "Epoch [1274/2000], Step [1/3], Loss: 502143.5000\n",
            "Epoch [1275/2000], Step [1/3], Loss: 502720.7500\n",
            "Epoch [1276/2000], Step [1/3], Loss: 503538.2188\n",
            "Epoch [1277/2000], Step [1/3], Loss: 504403.0312\n",
            "Epoch [1278/2000], Step [1/3], Loss: 500651.0625\n",
            "Epoch [1279/2000], Step [1/3], Loss: 500062.8750\n",
            "Epoch [1280/2000], Step [1/3], Loss: 502240.0000\n",
            "Epoch [1281/2000], Step [1/3], Loss: 502308.0000\n",
            "Epoch [1282/2000], Step [1/3], Loss: 501869.5000\n",
            "Epoch [1283/2000], Step [1/3], Loss: 500154.4688\n",
            "Epoch [1284/2000], Step [1/3], Loss: 499289.6250\n",
            "Epoch [1285/2000], Step [1/3], Loss: 504363.6562\n",
            "Epoch [1286/2000], Step [1/3], Loss: 504161.1562\n",
            "Epoch [1287/2000], Step [1/3], Loss: 502217.0312\n",
            "Epoch [1288/2000], Step [1/3], Loss: 503935.0938\n",
            "Epoch [1289/2000], Step [1/3], Loss: 500836.2812\n",
            "Epoch [1290/2000], Step [1/3], Loss: 502299.7188\n",
            "Epoch [1291/2000], Step [1/3], Loss: 500895.4062\n",
            "Epoch [1292/2000], Step [1/3], Loss: 502935.3438\n",
            "Epoch [1293/2000], Step [1/3], Loss: 503088.5625\n",
            "Epoch [1294/2000], Step [1/3], Loss: 502429.6875\n",
            "Epoch [1295/2000], Step [1/3], Loss: 502952.5000\n",
            "Epoch [1296/2000], Step [1/3], Loss: 503516.5000\n",
            "Epoch [1297/2000], Step [1/3], Loss: 502098.3750\n",
            "Epoch [1298/2000], Step [1/3], Loss: 500756.6875\n",
            "Epoch [1299/2000], Step [1/3], Loss: 500526.8750\n",
            "Epoch [1300/2000], Step [1/3], Loss: 501079.0312\n",
            "Epoch [1301/2000], Step [1/3], Loss: 500130.0000\n",
            "Epoch [1302/2000], Step [1/3], Loss: 501451.4375\n",
            "Epoch [1303/2000], Step [1/3], Loss: 500164.6562\n",
            "Epoch [1304/2000], Step [1/3], Loss: 503773.3750\n",
            "Epoch [1305/2000], Step [1/3], Loss: 501866.6562\n",
            "Epoch [1306/2000], Step [1/3], Loss: 499072.6562\n",
            "Epoch [1307/2000], Step [1/3], Loss: 499444.8125\n",
            "Epoch [1308/2000], Step [1/3], Loss: 499850.2188\n",
            "Epoch [1309/2000], Step [1/3], Loss: 503682.6250\n",
            "Epoch [1310/2000], Step [1/3], Loss: 504095.4062\n",
            "Epoch [1311/2000], Step [1/3], Loss: 502512.8438\n",
            "Epoch [1312/2000], Step [1/3], Loss: 498833.2812\n",
            "Epoch [1313/2000], Step [1/3], Loss: 499897.4688\n",
            "Epoch [1314/2000], Step [1/3], Loss: 499280.8125\n",
            "Epoch [1315/2000], Step [1/3], Loss: 499356.4375\n",
            "Epoch [1316/2000], Step [1/3], Loss: 503256.6875\n",
            "Epoch [1317/2000], Step [1/3], Loss: 501359.5000\n",
            "Epoch [1318/2000], Step [1/3], Loss: 498947.0000\n",
            "Epoch [1319/2000], Step [1/3], Loss: 502585.6562\n",
            "Epoch [1320/2000], Step [1/3], Loss: 500579.6875\n",
            "Epoch [1321/2000], Step [1/3], Loss: 500754.3125\n",
            "Epoch [1322/2000], Step [1/3], Loss: 502814.3438\n",
            "Epoch [1323/2000], Step [1/3], Loss: 502607.9375\n",
            "Epoch [1324/2000], Step [1/3], Loss: 502452.3750\n",
            "Epoch [1325/2000], Step [1/3], Loss: 502103.4375\n",
            "Epoch [1326/2000], Step [1/3], Loss: 502764.5625\n",
            "Epoch [1327/2000], Step [1/3], Loss: 501153.9688\n",
            "Epoch [1328/2000], Step [1/3], Loss: 502322.7500\n",
            "Epoch [1329/2000], Step [1/3], Loss: 502275.1875\n",
            "Epoch [1330/2000], Step [1/3], Loss: 502797.4375\n",
            "Epoch [1331/2000], Step [1/3], Loss: 503798.0000\n",
            "Epoch [1332/2000], Step [1/3], Loss: 498741.3750\n",
            "Epoch [1333/2000], Step [1/3], Loss: 501255.8125\n",
            "Epoch [1334/2000], Step [1/3], Loss: 500828.5312\n",
            "Epoch [1335/2000], Step [1/3], Loss: 505307.6250\n",
            "Epoch [1336/2000], Step [1/3], Loss: 499857.7188\n",
            "Epoch [1337/2000], Step [1/3], Loss: 502114.9375\n",
            "Epoch [1338/2000], Step [1/3], Loss: 501980.5938\n",
            "Epoch [1339/2000], Step [1/3], Loss: 503107.4375\n",
            "Epoch [1340/2000], Step [1/3], Loss: 500920.8125\n",
            "Epoch [1341/2000], Step [1/3], Loss: 499024.7500\n",
            "Epoch [1342/2000], Step [1/3], Loss: 497571.5312\n",
            "Epoch [1343/2000], Step [1/3], Loss: 499182.1875\n",
            "Epoch [1344/2000], Step [1/3], Loss: 500466.0625\n",
            "Epoch [1345/2000], Step [1/3], Loss: 502859.1562\n",
            "Epoch [1346/2000], Step [1/3], Loss: 503403.2500\n",
            "Epoch [1347/2000], Step [1/3], Loss: 500802.8750\n",
            "Epoch [1348/2000], Step [1/3], Loss: 499713.6562\n",
            "Epoch [1349/2000], Step [1/3], Loss: 499235.8125\n",
            "Epoch [1350/2000], Step [1/3], Loss: 500453.5000\n",
            "Epoch [1351/2000], Step [1/3], Loss: 502797.7812\n",
            "Epoch [1352/2000], Step [1/3], Loss: 500811.3750\n",
            "Epoch [1353/2000], Step [1/3], Loss: 501996.2188\n",
            "Epoch [1354/2000], Step [1/3], Loss: 502356.2500\n",
            "Epoch [1355/2000], Step [1/3], Loss: 499513.7500\n",
            "Epoch [1356/2000], Step [1/3], Loss: 501646.0000\n",
            "Epoch [1357/2000], Step [1/3], Loss: 501963.5000\n",
            "Epoch [1358/2000], Step [1/3], Loss: 502228.9062\n",
            "Epoch [1359/2000], Step [1/3], Loss: 501712.0625\n",
            "Epoch [1360/2000], Step [1/3], Loss: 500866.8750\n",
            "Epoch [1361/2000], Step [1/3], Loss: 501395.7500\n",
            "Epoch [1362/2000], Step [1/3], Loss: 500982.0938\n",
            "Epoch [1363/2000], Step [1/3], Loss: 499271.1250\n",
            "Epoch [1364/2000], Step [1/3], Loss: 499448.5938\n",
            "Epoch [1365/2000], Step [1/3], Loss: 501078.6250\n",
            "Epoch [1366/2000], Step [1/3], Loss: 498449.9375\n",
            "Epoch [1367/2000], Step [1/3], Loss: 499568.0938\n",
            "Epoch [1368/2000], Step [1/3], Loss: 501586.3750\n",
            "Epoch [1369/2000], Step [1/3], Loss: 498759.1250\n",
            "Epoch [1370/2000], Step [1/3], Loss: 500995.5312\n",
            "Epoch [1371/2000], Step [1/3], Loss: 500235.8750\n",
            "Epoch [1372/2000], Step [1/3], Loss: 500335.2188\n",
            "Epoch [1373/2000], Step [1/3], Loss: 501564.4688\n",
            "Epoch [1374/2000], Step [1/3], Loss: 501433.9688\n",
            "Epoch [1375/2000], Step [1/3], Loss: 501580.4375\n",
            "Epoch [1376/2000], Step [1/3], Loss: 502589.7500\n",
            "Epoch [1377/2000], Step [1/3], Loss: 502616.0625\n",
            "Epoch [1378/2000], Step [1/3], Loss: 500333.3438\n",
            "Epoch [1379/2000], Step [1/3], Loss: 503531.7812\n",
            "Epoch [1380/2000], Step [1/3], Loss: 501276.6250\n",
            "Epoch [1381/2000], Step [1/3], Loss: 502356.8438\n",
            "Epoch [1382/2000], Step [1/3], Loss: 499348.8438\n",
            "Epoch [1383/2000], Step [1/3], Loss: 498128.0625\n",
            "Epoch [1384/2000], Step [1/3], Loss: 501734.7812\n",
            "Epoch [1385/2000], Step [1/3], Loss: 500926.0625\n",
            "Epoch [1386/2000], Step [1/3], Loss: 499948.7188\n",
            "Epoch [1387/2000], Step [1/3], Loss: 501589.3438\n",
            "Epoch [1388/2000], Step [1/3], Loss: 501032.0000\n",
            "Epoch [1389/2000], Step [1/3], Loss: 501620.4062\n",
            "Epoch [1390/2000], Step [1/3], Loss: 504029.8750\n",
            "Epoch [1391/2000], Step [1/3], Loss: 498791.8125\n",
            "Epoch [1392/2000], Step [1/3], Loss: 502109.7500\n",
            "Epoch [1393/2000], Step [1/3], Loss: 500323.7188\n",
            "Epoch [1394/2000], Step [1/3], Loss: 501784.7812\n",
            "Epoch [1395/2000], Step [1/3], Loss: 502693.4688\n",
            "Epoch [1396/2000], Step [1/3], Loss: 499729.9688\n",
            "Epoch [1397/2000], Step [1/3], Loss: 501606.3125\n",
            "Epoch [1398/2000], Step [1/3], Loss: 502604.4375\n",
            "Epoch [1399/2000], Step [1/3], Loss: 500260.6250\n",
            "Epoch [1400/2000], Step [1/3], Loss: 501563.2188\n",
            "Epoch [1401/2000], Step [1/3], Loss: 500879.6875\n",
            "Epoch [1402/2000], Step [1/3], Loss: 502986.7812\n",
            "Epoch [1403/2000], Step [1/3], Loss: 497659.9375\n",
            "Epoch [1404/2000], Step [1/3], Loss: 500129.9375\n",
            "Epoch [1405/2000], Step [1/3], Loss: 499843.8438\n",
            "Epoch [1406/2000], Step [1/3], Loss: 501180.8438\n",
            "Epoch [1407/2000], Step [1/3], Loss: 503261.7188\n",
            "Epoch [1408/2000], Step [1/3], Loss: 501382.6562\n",
            "Epoch [1409/2000], Step [1/3], Loss: 501163.8125\n",
            "Epoch [1410/2000], Step [1/3], Loss: 502664.7188\n",
            "Epoch [1411/2000], Step [1/3], Loss: 500736.6250\n",
            "Epoch [1412/2000], Step [1/3], Loss: 501708.1562\n",
            "Epoch [1413/2000], Step [1/3], Loss: 502135.8125\n",
            "Epoch [1414/2000], Step [1/3], Loss: 499244.8750\n",
            "Epoch [1415/2000], Step [1/3], Loss: 500595.4688\n",
            "Epoch [1416/2000], Step [1/3], Loss: 500396.5938\n",
            "Epoch [1417/2000], Step [1/3], Loss: 501719.4688\n",
            "Epoch [1418/2000], Step [1/3], Loss: 502964.1250\n",
            "Epoch [1419/2000], Step [1/3], Loss: 499565.8750\n",
            "Epoch [1420/2000], Step [1/3], Loss: 501131.8125\n",
            "Epoch [1421/2000], Step [1/3], Loss: 498965.3750\n",
            "Epoch [1422/2000], Step [1/3], Loss: 501880.9375\n",
            "Epoch [1423/2000], Step [1/3], Loss: 500719.1250\n",
            "Epoch [1424/2000], Step [1/3], Loss: 503378.4375\n",
            "Epoch [1425/2000], Step [1/3], Loss: 502302.4688\n",
            "Epoch [1426/2000], Step [1/3], Loss: 501244.7188\n",
            "Epoch [1427/2000], Step [1/3], Loss: 501657.0625\n",
            "Epoch [1428/2000], Step [1/3], Loss: 498934.2500\n",
            "Epoch [1429/2000], Step [1/3], Loss: 502776.5938\n",
            "Epoch [1430/2000], Step [1/3], Loss: 502202.5312\n",
            "Epoch [1431/2000], Step [1/3], Loss: 498178.8125\n",
            "Epoch [1432/2000], Step [1/3], Loss: 501400.4688\n",
            "Epoch [1433/2000], Step [1/3], Loss: 501926.7188\n",
            "Epoch [1434/2000], Step [1/3], Loss: 501805.0312\n",
            "Epoch [1435/2000], Step [1/3], Loss: 501932.1250\n",
            "Epoch [1436/2000], Step [1/3], Loss: 501036.2812\n",
            "Epoch [1437/2000], Step [1/3], Loss: 501120.1875\n",
            "Epoch [1438/2000], Step [1/3], Loss: 504638.1875\n",
            "Epoch [1439/2000], Step [1/3], Loss: 500491.9688\n",
            "Epoch [1440/2000], Step [1/3], Loss: 499970.5625\n",
            "Epoch [1441/2000], Step [1/3], Loss: 498557.0000\n",
            "Epoch [1442/2000], Step [1/3], Loss: 501875.8750\n",
            "Epoch [1443/2000], Step [1/3], Loss: 501519.4688\n",
            "Epoch [1444/2000], Step [1/3], Loss: 502175.0625\n",
            "Epoch [1445/2000], Step [1/3], Loss: 501267.1875\n",
            "Epoch [1446/2000], Step [1/3], Loss: 500512.0000\n",
            "Epoch [1447/2000], Step [1/3], Loss: 499492.5625\n",
            "Epoch [1448/2000], Step [1/3], Loss: 500790.0625\n",
            "Epoch [1449/2000], Step [1/3], Loss: 503175.6875\n",
            "Epoch [1450/2000], Step [1/3], Loss: 501675.1250\n",
            "Epoch [1451/2000], Step [1/3], Loss: 503219.4375\n",
            "Epoch [1452/2000], Step [1/3], Loss: 501508.3750\n",
            "Epoch [1453/2000], Step [1/3], Loss: 500807.2188\n",
            "Epoch [1454/2000], Step [1/3], Loss: 501628.6562\n",
            "Epoch [1455/2000], Step [1/3], Loss: 501079.4688\n",
            "Epoch [1456/2000], Step [1/3], Loss: 500353.8750\n",
            "Epoch [1457/2000], Step [1/3], Loss: 498868.0938\n",
            "Epoch [1458/2000], Step [1/3], Loss: 500099.8438\n",
            "Epoch [1459/2000], Step [1/3], Loss: 502476.9375\n",
            "Epoch [1460/2000], Step [1/3], Loss: 500003.8125\n",
            "Epoch [1461/2000], Step [1/3], Loss: 502032.4375\n",
            "Epoch [1462/2000], Step [1/3], Loss: 499839.8750\n",
            "Epoch [1463/2000], Step [1/3], Loss: 500233.5000\n",
            "Epoch [1464/2000], Step [1/3], Loss: 501685.1875\n",
            "Epoch [1465/2000], Step [1/3], Loss: 499606.8438\n",
            "Epoch [1466/2000], Step [1/3], Loss: 500866.0625\n",
            "Epoch [1467/2000], Step [1/3], Loss: 500522.6562\n",
            "Epoch [1468/2000], Step [1/3], Loss: 499309.0938\n",
            "Epoch [1469/2000], Step [1/3], Loss: 501318.2500\n",
            "Epoch [1470/2000], Step [1/3], Loss: 500134.7500\n",
            "Epoch [1471/2000], Step [1/3], Loss: 500431.2500\n",
            "Epoch [1472/2000], Step [1/3], Loss: 500184.6875\n",
            "Epoch [1473/2000], Step [1/3], Loss: 501640.6562\n",
            "Epoch [1474/2000], Step [1/3], Loss: 502672.4375\n",
            "Epoch [1475/2000], Step [1/3], Loss: 500696.3750\n",
            "Epoch [1476/2000], Step [1/3], Loss: 499582.6562\n",
            "Epoch [1477/2000], Step [1/3], Loss: 501479.5625\n",
            "Epoch [1478/2000], Step [1/3], Loss: 500490.0938\n",
            "Epoch [1479/2000], Step [1/3], Loss: 499725.2500\n",
            "Epoch [1480/2000], Step [1/3], Loss: 502474.5000\n",
            "Epoch [1481/2000], Step [1/3], Loss: 499964.9688\n",
            "Epoch [1482/2000], Step [1/3], Loss: 501490.9375\n",
            "Epoch [1483/2000], Step [1/3], Loss: 500800.7500\n",
            "Epoch [1484/2000], Step [1/3], Loss: 501816.6875\n",
            "Epoch [1485/2000], Step [1/3], Loss: 499562.2812\n",
            "Epoch [1486/2000], Step [1/3], Loss: 498117.7188\n",
            "Epoch [1487/2000], Step [1/3], Loss: 501047.6875\n",
            "Epoch [1488/2000], Step [1/3], Loss: 502041.5625\n",
            "Epoch [1489/2000], Step [1/3], Loss: 500974.7812\n",
            "Epoch [1490/2000], Step [1/3], Loss: 499139.1875\n",
            "Epoch [1491/2000], Step [1/3], Loss: 501964.4688\n",
            "Epoch [1492/2000], Step [1/3], Loss: 500057.3750\n",
            "Epoch [1493/2000], Step [1/3], Loss: 502795.4375\n",
            "Epoch [1494/2000], Step [1/3], Loss: 498176.0000\n",
            "Epoch [1495/2000], Step [1/3], Loss: 499716.3125\n",
            "Epoch [1496/2000], Step [1/3], Loss: 500602.5625\n",
            "Epoch [1497/2000], Step [1/3], Loss: 499956.5312\n",
            "Epoch [1498/2000], Step [1/3], Loss: 502517.4688\n",
            "Epoch [1499/2000], Step [1/3], Loss: 502026.2188\n",
            "Epoch [1500/2000], Step [1/3], Loss: 503318.6562\n",
            "Epoch [1501/2000], Step [1/3], Loss: 499463.1562\n",
            "Epoch [1502/2000], Step [1/3], Loss: 500601.4375\n",
            "Epoch [1503/2000], Step [1/3], Loss: 500625.8438\n",
            "Epoch [1504/2000], Step [1/3], Loss: 500463.8438\n",
            "Epoch [1505/2000], Step [1/3], Loss: 500439.6250\n",
            "Epoch [1506/2000], Step [1/3], Loss: 500907.1562\n",
            "Epoch [1507/2000], Step [1/3], Loss: 502448.5312\n",
            "Epoch [1508/2000], Step [1/3], Loss: 499520.6250\n",
            "Epoch [1509/2000], Step [1/3], Loss: 502894.0625\n",
            "Epoch [1510/2000], Step [1/3], Loss: 500030.4688\n",
            "Epoch [1511/2000], Step [1/3], Loss: 498503.2188\n",
            "Epoch [1512/2000], Step [1/3], Loss: 501545.3438\n",
            "Epoch [1513/2000], Step [1/3], Loss: 499530.3750\n",
            "Epoch [1514/2000], Step [1/3], Loss: 502022.5000\n",
            "Epoch [1515/2000], Step [1/3], Loss: 501013.2812\n",
            "Epoch [1516/2000], Step [1/3], Loss: 503805.9062\n",
            "Epoch [1517/2000], Step [1/3], Loss: 500391.9688\n",
            "Epoch [1518/2000], Step [1/3], Loss: 499305.9688\n",
            "Epoch [1519/2000], Step [1/3], Loss: 502188.4375\n",
            "Epoch [1520/2000], Step [1/3], Loss: 498956.2500\n",
            "Epoch [1521/2000], Step [1/3], Loss: 501119.2812\n",
            "Epoch [1522/2000], Step [1/3], Loss: 502151.0625\n",
            "Epoch [1523/2000], Step [1/3], Loss: 499448.0312\n",
            "Epoch [1524/2000], Step [1/3], Loss: 503280.0938\n",
            "Epoch [1525/2000], Step [1/3], Loss: 498299.8750\n",
            "Epoch [1526/2000], Step [1/3], Loss: 499752.2812\n",
            "Epoch [1527/2000], Step [1/3], Loss: 503867.0000\n",
            "Epoch [1528/2000], Step [1/3], Loss: 502888.7500\n",
            "Epoch [1529/2000], Step [1/3], Loss: 500440.4375\n",
            "Epoch [1530/2000], Step [1/3], Loss: 500433.2500\n",
            "Epoch [1531/2000], Step [1/3], Loss: 502073.0000\n",
            "Epoch [1532/2000], Step [1/3], Loss: 500680.4688\n",
            "Epoch [1533/2000], Step [1/3], Loss: 501544.3750\n",
            "Epoch [1534/2000], Step [1/3], Loss: 500059.1562\n",
            "Epoch [1535/2000], Step [1/3], Loss: 498393.1875\n",
            "Epoch [1536/2000], Step [1/3], Loss: 498349.4062\n",
            "Epoch [1537/2000], Step [1/3], Loss: 497588.6562\n",
            "Epoch [1538/2000], Step [1/3], Loss: 502438.6875\n",
            "Epoch [1539/2000], Step [1/3], Loss: 502291.4062\n",
            "Epoch [1540/2000], Step [1/3], Loss: 503002.0625\n",
            "Epoch [1541/2000], Step [1/3], Loss: 500191.8438\n",
            "Epoch [1542/2000], Step [1/3], Loss: 500733.7188\n",
            "Epoch [1543/2000], Step [1/3], Loss: 499529.0000\n",
            "Epoch [1544/2000], Step [1/3], Loss: 499587.8125\n",
            "Epoch [1545/2000], Step [1/3], Loss: 499352.1562\n",
            "Epoch [1546/2000], Step [1/3], Loss: 501045.3438\n",
            "Epoch [1547/2000], Step [1/3], Loss: 500452.4062\n",
            "Epoch [1548/2000], Step [1/3], Loss: 499121.9062\n",
            "Epoch [1549/2000], Step [1/3], Loss: 500211.4375\n",
            "Epoch [1550/2000], Step [1/3], Loss: 500363.3125\n",
            "Epoch [1551/2000], Step [1/3], Loss: 501608.8750\n",
            "Epoch [1552/2000], Step [1/3], Loss: 500867.6875\n",
            "Epoch [1553/2000], Step [1/3], Loss: 503062.9375\n",
            "Epoch [1554/2000], Step [1/3], Loss: 498304.5938\n",
            "Epoch [1555/2000], Step [1/3], Loss: 500884.5625\n",
            "Epoch [1556/2000], Step [1/3], Loss: 501728.4062\n",
            "Epoch [1557/2000], Step [1/3], Loss: 503028.6250\n",
            "Epoch [1558/2000], Step [1/3], Loss: 500809.9375\n",
            "Epoch [1559/2000], Step [1/3], Loss: 500037.5312\n",
            "Epoch [1560/2000], Step [1/3], Loss: 499008.8125\n",
            "Epoch [1561/2000], Step [1/3], Loss: 500765.8438\n",
            "Epoch [1562/2000], Step [1/3], Loss: 499283.4688\n",
            "Epoch [1563/2000], Step [1/3], Loss: 500405.3438\n",
            "Epoch [1564/2000], Step [1/3], Loss: 502409.0000\n",
            "Epoch [1565/2000], Step [1/3], Loss: 501942.9688\n",
            "Epoch [1566/2000], Step [1/3], Loss: 501050.0625\n",
            "Epoch [1567/2000], Step [1/3], Loss: 501193.1875\n",
            "Epoch [1568/2000], Step [1/3], Loss: 500751.9688\n",
            "Epoch [1569/2000], Step [1/3], Loss: 502834.7188\n",
            "Epoch [1570/2000], Step [1/3], Loss: 501165.5938\n",
            "Epoch [1571/2000], Step [1/3], Loss: 502378.0938\n",
            "Epoch [1572/2000], Step [1/3], Loss: 500066.0312\n",
            "Epoch [1573/2000], Step [1/3], Loss: 501030.6250\n",
            "Epoch [1574/2000], Step [1/3], Loss: 500441.4375\n",
            "Epoch [1575/2000], Step [1/3], Loss: 503159.5938\n",
            "Epoch [1576/2000], Step [1/3], Loss: 501957.4375\n",
            "Epoch [1577/2000], Step [1/3], Loss: 500298.7188\n",
            "Epoch [1578/2000], Step [1/3], Loss: 502309.4062\n",
            "Epoch [1579/2000], Step [1/3], Loss: 500499.8750\n",
            "Epoch [1580/2000], Step [1/3], Loss: 499561.8125\n",
            "Epoch [1581/2000], Step [1/3], Loss: 500106.0000\n",
            "Epoch [1582/2000], Step [1/3], Loss: 501019.4375\n",
            "Epoch [1583/2000], Step [1/3], Loss: 500353.1562\n",
            "Epoch [1584/2000], Step [1/3], Loss: 502900.2188\n",
            "Epoch [1585/2000], Step [1/3], Loss: 501389.3125\n",
            "Epoch [1586/2000], Step [1/3], Loss: 503740.6562\n",
            "Epoch [1587/2000], Step [1/3], Loss: 501181.6875\n",
            "Epoch [1588/2000], Step [1/3], Loss: 501716.9688\n",
            "Epoch [1589/2000], Step [1/3], Loss: 500141.6250\n",
            "Epoch [1590/2000], Step [1/3], Loss: 498595.3125\n",
            "Epoch [1591/2000], Step [1/3], Loss: 501352.8750\n",
            "Epoch [1592/2000], Step [1/3], Loss: 499718.5312\n",
            "Epoch [1593/2000], Step [1/3], Loss: 500605.1875\n",
            "Epoch [1594/2000], Step [1/3], Loss: 501572.3750\n",
            "Epoch [1595/2000], Step [1/3], Loss: 501771.1875\n",
            "Epoch [1596/2000], Step [1/3], Loss: 500954.2500\n",
            "Epoch [1597/2000], Step [1/3], Loss: 498785.4688\n",
            "Epoch [1598/2000], Step [1/3], Loss: 501185.9062\n",
            "Epoch [1599/2000], Step [1/3], Loss: 502161.5625\n",
            "Epoch [1600/2000], Step [1/3], Loss: 499971.0000\n",
            "Epoch [1601/2000], Step [1/3], Loss: 497877.8438\n",
            "Epoch [1602/2000], Step [1/3], Loss: 497767.8125\n",
            "Epoch [1603/2000], Step [1/3], Loss: 499842.5312\n",
            "Epoch [1604/2000], Step [1/3], Loss: 502417.5625\n",
            "Epoch [1605/2000], Step [1/3], Loss: 500255.4062\n",
            "Epoch [1606/2000], Step [1/3], Loss: 503312.0938\n",
            "Epoch [1607/2000], Step [1/3], Loss: 500276.2812\n",
            "Epoch [1608/2000], Step [1/3], Loss: 500928.5000\n",
            "Epoch [1609/2000], Step [1/3], Loss: 498364.2812\n",
            "Epoch [1610/2000], Step [1/3], Loss: 501167.7500\n",
            "Epoch [1611/2000], Step [1/3], Loss: 503549.2188\n",
            "Epoch [1612/2000], Step [1/3], Loss: 502001.0000\n",
            "Epoch [1613/2000], Step [1/3], Loss: 500239.1250\n",
            "Epoch [1614/2000], Step [1/3], Loss: 499672.8125\n",
            "Epoch [1615/2000], Step [1/3], Loss: 503113.5000\n",
            "Epoch [1616/2000], Step [1/3], Loss: 499294.0000\n",
            "Epoch [1617/2000], Step [1/3], Loss: 503168.5625\n",
            "Epoch [1618/2000], Step [1/3], Loss: 499779.5625\n",
            "Epoch [1619/2000], Step [1/3], Loss: 499962.9688\n",
            "Epoch [1620/2000], Step [1/3], Loss: 501896.3438\n",
            "Epoch [1621/2000], Step [1/3], Loss: 500601.8438\n",
            "Epoch [1622/2000], Step [1/3], Loss: 501073.0625\n",
            "Epoch [1623/2000], Step [1/3], Loss: 500861.0312\n",
            "Epoch [1624/2000], Step [1/3], Loss: 503200.5312\n",
            "Epoch [1625/2000], Step [1/3], Loss: 500231.3438\n",
            "Epoch [1626/2000], Step [1/3], Loss: 500073.0000\n",
            "Epoch [1627/2000], Step [1/3], Loss: 502135.5625\n",
            "Epoch [1628/2000], Step [1/3], Loss: 499840.5625\n",
            "Epoch [1629/2000], Step [1/3], Loss: 499845.6562\n",
            "Epoch [1630/2000], Step [1/3], Loss: 499717.0312\n",
            "Epoch [1631/2000], Step [1/3], Loss: 500839.2500\n",
            "Epoch [1632/2000], Step [1/3], Loss: 501882.7188\n",
            "Epoch [1633/2000], Step [1/3], Loss: 499990.6562\n",
            "Epoch [1634/2000], Step [1/3], Loss: 502452.5312\n",
            "Epoch [1635/2000], Step [1/3], Loss: 502279.5938\n",
            "Epoch [1636/2000], Step [1/3], Loss: 499719.2812\n",
            "Epoch [1637/2000], Step [1/3], Loss: 498886.5938\n",
            "Epoch [1638/2000], Step [1/3], Loss: 499393.6562\n",
            "Epoch [1639/2000], Step [1/3], Loss: 501399.5000\n",
            "Epoch [1640/2000], Step [1/3], Loss: 500943.7188\n",
            "Epoch [1641/2000], Step [1/3], Loss: 501227.6250\n",
            "Epoch [1642/2000], Step [1/3], Loss: 501977.4688\n",
            "Epoch [1643/2000], Step [1/3], Loss: 500926.1875\n",
            "Epoch [1644/2000], Step [1/3], Loss: 500805.3438\n",
            "Epoch [1645/2000], Step [1/3], Loss: 500173.4688\n",
            "Epoch [1646/2000], Step [1/3], Loss: 499040.3750\n",
            "Epoch [1647/2000], Step [1/3], Loss: 501306.4688\n",
            "Epoch [1648/2000], Step [1/3], Loss: 499646.8125\n",
            "Epoch [1649/2000], Step [1/3], Loss: 500059.4375\n",
            "Epoch [1650/2000], Step [1/3], Loss: 498954.5000\n",
            "Epoch [1651/2000], Step [1/3], Loss: 500296.5625\n",
            "Epoch [1652/2000], Step [1/3], Loss: 501816.5000\n",
            "Epoch [1653/2000], Step [1/3], Loss: 501831.8125\n",
            "Epoch [1654/2000], Step [1/3], Loss: 501776.6562\n",
            "Epoch [1655/2000], Step [1/3], Loss: 501040.0312\n",
            "Epoch [1656/2000], Step [1/3], Loss: 501897.6250\n",
            "Epoch [1657/2000], Step [1/3], Loss: 499980.0625\n",
            "Epoch [1658/2000], Step [1/3], Loss: 501160.8438\n",
            "Epoch [1659/2000], Step [1/3], Loss: 503379.4062\n",
            "Epoch [1660/2000], Step [1/3], Loss: 502022.7812\n",
            "Epoch [1661/2000], Step [1/3], Loss: 497408.6875\n",
            "Epoch [1662/2000], Step [1/3], Loss: 501838.0000\n",
            "Epoch [1663/2000], Step [1/3], Loss: 500930.4375\n",
            "Epoch [1664/2000], Step [1/3], Loss: 499569.7812\n",
            "Epoch [1665/2000], Step [1/3], Loss: 498542.5938\n",
            "Epoch [1666/2000], Step [1/3], Loss: 501063.9375\n",
            "Epoch [1667/2000], Step [1/3], Loss: 501143.7812\n",
            "Epoch [1668/2000], Step [1/3], Loss: 501821.5938\n",
            "Epoch [1669/2000], Step [1/3], Loss: 500058.3750\n",
            "Epoch [1670/2000], Step [1/3], Loss: 498262.0000\n",
            "Epoch [1671/2000], Step [1/3], Loss: 499679.5938\n",
            "Epoch [1672/2000], Step [1/3], Loss: 501189.7812\n",
            "Epoch [1673/2000], Step [1/3], Loss: 498955.4688\n",
            "Epoch [1674/2000], Step [1/3], Loss: 500777.8125\n",
            "Epoch [1675/2000], Step [1/3], Loss: 499692.6875\n",
            "Epoch [1676/2000], Step [1/3], Loss: 501676.5000\n",
            "Epoch [1677/2000], Step [1/3], Loss: 497148.1562\n",
            "Epoch [1678/2000], Step [1/3], Loss: 500851.3750\n",
            "Epoch [1679/2000], Step [1/3], Loss: 502042.0938\n",
            "Epoch [1680/2000], Step [1/3], Loss: 501734.6875\n",
            "Epoch [1681/2000], Step [1/3], Loss: 500302.6875\n",
            "Epoch [1682/2000], Step [1/3], Loss: 499136.0938\n",
            "Epoch [1683/2000], Step [1/3], Loss: 498866.8438\n",
            "Epoch [1684/2000], Step [1/3], Loss: 498969.9375\n",
            "Epoch [1685/2000], Step [1/3], Loss: 501832.0000\n",
            "Epoch [1686/2000], Step [1/3], Loss: 501076.8750\n",
            "Epoch [1687/2000], Step [1/3], Loss: 501151.9375\n",
            "Epoch [1688/2000], Step [1/3], Loss: 499588.8750\n",
            "Epoch [1689/2000], Step [1/3], Loss: 501115.6875\n",
            "Epoch [1690/2000], Step [1/3], Loss: 501808.2188\n",
            "Epoch [1691/2000], Step [1/3], Loss: 498843.4375\n",
            "Epoch [1692/2000], Step [1/3], Loss: 497768.0625\n",
            "Epoch [1693/2000], Step [1/3], Loss: 502440.6875\n",
            "Epoch [1694/2000], Step [1/3], Loss: 500201.8438\n",
            "Epoch [1695/2000], Step [1/3], Loss: 501331.2812\n",
            "Epoch [1696/2000], Step [1/3], Loss: 504340.2500\n",
            "Epoch [1697/2000], Step [1/3], Loss: 500105.2500\n",
            "Epoch [1698/2000], Step [1/3], Loss: 504029.7812\n",
            "Epoch [1699/2000], Step [1/3], Loss: 499314.1562\n",
            "Epoch [1700/2000], Step [1/3], Loss: 502161.2500\n",
            "Epoch [1701/2000], Step [1/3], Loss: 500657.4688\n",
            "Epoch [1702/2000], Step [1/3], Loss: 502484.5625\n",
            "Epoch [1703/2000], Step [1/3], Loss: 501258.2812\n",
            "Epoch [1704/2000], Step [1/3], Loss: 502332.6875\n",
            "Epoch [1705/2000], Step [1/3], Loss: 503861.6250\n",
            "Epoch [1706/2000], Step [1/3], Loss: 499587.2188\n",
            "Epoch [1707/2000], Step [1/3], Loss: 500019.5000\n",
            "Epoch [1708/2000], Step [1/3], Loss: 499852.2188\n",
            "Epoch [1709/2000], Step [1/3], Loss: 499432.0000\n",
            "Epoch [1710/2000], Step [1/3], Loss: 500949.8125\n",
            "Epoch [1711/2000], Step [1/3], Loss: 503461.8438\n",
            "Epoch [1712/2000], Step [1/3], Loss: 498427.3750\n",
            "Epoch [1713/2000], Step [1/3], Loss: 499878.6562\n",
            "Epoch [1714/2000], Step [1/3], Loss: 499973.8438\n",
            "Epoch [1715/2000], Step [1/3], Loss: 499679.5625\n",
            "Epoch [1716/2000], Step [1/3], Loss: 499626.5625\n",
            "Epoch [1717/2000], Step [1/3], Loss: 499733.9688\n",
            "Epoch [1718/2000], Step [1/3], Loss: 501056.0625\n",
            "Epoch [1719/2000], Step [1/3], Loss: 499918.9062\n",
            "Epoch [1720/2000], Step [1/3], Loss: 501378.6250\n",
            "Epoch [1721/2000], Step [1/3], Loss: 503564.9062\n",
            "Epoch [1722/2000], Step [1/3], Loss: 501893.4688\n",
            "Epoch [1723/2000], Step [1/3], Loss: 499692.9062\n",
            "Epoch [1724/2000], Step [1/3], Loss: 500778.1250\n",
            "Epoch [1725/2000], Step [1/3], Loss: 498810.7188\n",
            "Epoch [1726/2000], Step [1/3], Loss: 501400.6250\n",
            "Epoch [1727/2000], Step [1/3], Loss: 502349.9688\n",
            "Epoch [1728/2000], Step [1/3], Loss: 499011.4688\n",
            "Epoch [1729/2000], Step [1/3], Loss: 501800.6250\n",
            "Epoch [1730/2000], Step [1/3], Loss: 501628.4688\n",
            "Epoch [1731/2000], Step [1/3], Loss: 499502.1875\n",
            "Epoch [1732/2000], Step [1/3], Loss: 499706.4375\n",
            "Epoch [1733/2000], Step [1/3], Loss: 499972.8438\n",
            "Epoch [1734/2000], Step [1/3], Loss: 498897.9688\n",
            "Epoch [1735/2000], Step [1/3], Loss: 498123.6875\n",
            "Epoch [1736/2000], Step [1/3], Loss: 498416.1562\n",
            "Epoch [1737/2000], Step [1/3], Loss: 499736.4375\n",
            "Epoch [1738/2000], Step [1/3], Loss: 500452.1875\n",
            "Epoch [1739/2000], Step [1/3], Loss: 501632.5312\n",
            "Epoch [1740/2000], Step [1/3], Loss: 500837.2500\n",
            "Epoch [1741/2000], Step [1/3], Loss: 501224.2188\n",
            "Epoch [1742/2000], Step [1/3], Loss: 499959.5938\n",
            "Epoch [1743/2000], Step [1/3], Loss: 499491.7812\n",
            "Epoch [1744/2000], Step [1/3], Loss: 500652.7188\n",
            "Epoch [1745/2000], Step [1/3], Loss: 498004.3750\n",
            "Epoch [1746/2000], Step [1/3], Loss: 501445.5312\n",
            "Epoch [1747/2000], Step [1/3], Loss: 500145.5000\n",
            "Epoch [1748/2000], Step [1/3], Loss: 499593.1562\n",
            "Epoch [1749/2000], Step [1/3], Loss: 502092.5000\n",
            "Epoch [1750/2000], Step [1/3], Loss: 500326.5625\n",
            "Epoch [1751/2000], Step [1/3], Loss: 499751.0938\n",
            "Epoch [1752/2000], Step [1/3], Loss: 499467.4375\n",
            "Epoch [1753/2000], Step [1/3], Loss: 501406.3750\n",
            "Epoch [1754/2000], Step [1/3], Loss: 501826.0625\n",
            "Epoch [1755/2000], Step [1/3], Loss: 499862.7500\n",
            "Epoch [1756/2000], Step [1/3], Loss: 497267.7188\n",
            "Epoch [1757/2000], Step [1/3], Loss: 502181.0312\n",
            "Epoch [1758/2000], Step [1/3], Loss: 502285.5625\n",
            "Epoch [1759/2000], Step [1/3], Loss: 501676.4688\n",
            "Epoch [1760/2000], Step [1/3], Loss: 501607.2500\n",
            "Epoch [1761/2000], Step [1/3], Loss: 500565.1562\n",
            "Epoch [1762/2000], Step [1/3], Loss: 499331.1875\n",
            "Epoch [1763/2000], Step [1/3], Loss: 501745.8750\n",
            "Epoch [1764/2000], Step [1/3], Loss: 500069.6250\n",
            "Epoch [1765/2000], Step [1/3], Loss: 499823.7188\n",
            "Epoch [1766/2000], Step [1/3], Loss: 500214.0625\n",
            "Epoch [1767/2000], Step [1/3], Loss: 501598.2188\n",
            "Epoch [1768/2000], Step [1/3], Loss: 499638.2500\n",
            "Epoch [1769/2000], Step [1/3], Loss: 503122.4688\n",
            "Epoch [1770/2000], Step [1/3], Loss: 502801.4375\n",
            "Epoch [1771/2000], Step [1/3], Loss: 497727.0625\n",
            "Epoch [1772/2000], Step [1/3], Loss: 497214.2188\n",
            "Epoch [1773/2000], Step [1/3], Loss: 500266.1250\n",
            "Epoch [1774/2000], Step [1/3], Loss: 501741.4375\n",
            "Epoch [1775/2000], Step [1/3], Loss: 499239.6562\n",
            "Epoch [1776/2000], Step [1/3], Loss: 502509.4688\n",
            "Epoch [1777/2000], Step [1/3], Loss: 499409.0312\n",
            "Epoch [1778/2000], Step [1/3], Loss: 501812.7188\n",
            "Epoch [1779/2000], Step [1/3], Loss: 497738.5312\n",
            "Epoch [1780/2000], Step [1/3], Loss: 500974.6562\n",
            "Epoch [1781/2000], Step [1/3], Loss: 499879.5312\n",
            "Epoch [1782/2000], Step [1/3], Loss: 500127.1562\n",
            "Epoch [1783/2000], Step [1/3], Loss: 500763.9375\n",
            "Epoch [1784/2000], Step [1/3], Loss: 499163.0312\n",
            "Epoch [1785/2000], Step [1/3], Loss: 497333.9688\n",
            "Epoch [1786/2000], Step [1/3], Loss: 502928.1562\n",
            "Epoch [1787/2000], Step [1/3], Loss: 499142.0312\n",
            "Epoch [1788/2000], Step [1/3], Loss: 499225.5625\n",
            "Epoch [1789/2000], Step [1/3], Loss: 500431.5312\n",
            "Epoch [1790/2000], Step [1/3], Loss: 502168.0000\n",
            "Epoch [1791/2000], Step [1/3], Loss: 498721.0000\n",
            "Epoch [1792/2000], Step [1/3], Loss: 500062.8750\n",
            "Epoch [1793/2000], Step [1/3], Loss: 503095.6250\n",
            "Epoch [1794/2000], Step [1/3], Loss: 498703.3750\n",
            "Epoch [1795/2000], Step [1/3], Loss: 499035.7812\n",
            "Epoch [1796/2000], Step [1/3], Loss: 498238.5312\n",
            "Epoch [1797/2000], Step [1/3], Loss: 498252.5312\n",
            "Epoch [1798/2000], Step [1/3], Loss: 498904.4062\n",
            "Epoch [1799/2000], Step [1/3], Loss: 499316.5625\n",
            "Epoch [1800/2000], Step [1/3], Loss: 498022.6562\n",
            "Epoch [1801/2000], Step [1/3], Loss: 503567.0312\n",
            "Epoch [1802/2000], Step [1/3], Loss: 499743.1250\n",
            "Epoch [1803/2000], Step [1/3], Loss: 500233.9688\n",
            "Epoch [1804/2000], Step [1/3], Loss: 498762.4062\n",
            "Epoch [1805/2000], Step [1/3], Loss: 501721.4062\n",
            "Epoch [1806/2000], Step [1/3], Loss: 500742.8125\n",
            "Epoch [1807/2000], Step [1/3], Loss: 498602.4688\n",
            "Epoch [1808/2000], Step [1/3], Loss: 499276.5000\n",
            "Epoch [1809/2000], Step [1/3], Loss: 498876.3750\n",
            "Epoch [1810/2000], Step [1/3], Loss: 500125.4062\n",
            "Epoch [1811/2000], Step [1/3], Loss: 499783.6250\n",
            "Epoch [1812/2000], Step [1/3], Loss: 500799.6562\n",
            "Epoch [1813/2000], Step [1/3], Loss: 501580.3438\n",
            "Epoch [1814/2000], Step [1/3], Loss: 501453.3125\n",
            "Epoch [1815/2000], Step [1/3], Loss: 499621.2500\n",
            "Epoch [1816/2000], Step [1/3], Loss: 501548.5312\n",
            "Epoch [1817/2000], Step [1/3], Loss: 498667.9688\n",
            "Epoch [1818/2000], Step [1/3], Loss: 499353.5938\n",
            "Epoch [1819/2000], Step [1/3], Loss: 499912.4375\n",
            "Epoch [1820/2000], Step [1/3], Loss: 500775.5312\n",
            "Epoch [1821/2000], Step [1/3], Loss: 499932.4375\n",
            "Epoch [1822/2000], Step [1/3], Loss: 502444.2188\n",
            "Epoch [1823/2000], Step [1/3], Loss: 498636.5000\n",
            "Epoch [1824/2000], Step [1/3], Loss: 499077.8750\n",
            "Epoch [1825/2000], Step [1/3], Loss: 501425.1562\n",
            "Epoch [1826/2000], Step [1/3], Loss: 499326.6562\n",
            "Epoch [1827/2000], Step [1/3], Loss: 500735.0312\n",
            "Epoch [1828/2000], Step [1/3], Loss: 499010.9062\n",
            "Epoch [1829/2000], Step [1/3], Loss: 500875.4688\n",
            "Epoch [1830/2000], Step [1/3], Loss: 501313.4062\n",
            "Epoch [1831/2000], Step [1/3], Loss: 500779.4062\n",
            "Epoch [1832/2000], Step [1/3], Loss: 499976.4688\n",
            "Epoch [1833/2000], Step [1/3], Loss: 499610.6875\n",
            "Epoch [1834/2000], Step [1/3], Loss: 500138.3125\n",
            "Epoch [1835/2000], Step [1/3], Loss: 500840.3438\n",
            "Epoch [1836/2000], Step [1/3], Loss: 500981.6250\n",
            "Epoch [1837/2000], Step [1/3], Loss: 500820.6250\n",
            "Epoch [1838/2000], Step [1/3], Loss: 499017.4375\n",
            "Epoch [1839/2000], Step [1/3], Loss: 500410.6250\n",
            "Epoch [1840/2000], Step [1/3], Loss: 499753.4375\n",
            "Epoch [1841/2000], Step [1/3], Loss: 498955.8125\n",
            "Epoch [1842/2000], Step [1/3], Loss: 499342.3125\n",
            "Epoch [1843/2000], Step [1/3], Loss: 500460.6875\n",
            "Epoch [1844/2000], Step [1/3], Loss: 501296.3438\n",
            "Epoch [1845/2000], Step [1/3], Loss: 499166.5312\n",
            "Epoch [1846/2000], Step [1/3], Loss: 499361.5312\n",
            "Epoch [1847/2000], Step [1/3], Loss: 500162.8750\n",
            "Epoch [1848/2000], Step [1/3], Loss: 499785.7188\n",
            "Epoch [1849/2000], Step [1/3], Loss: 499020.1250\n",
            "Epoch [1850/2000], Step [1/3], Loss: 499477.6875\n",
            "Epoch [1851/2000], Step [1/3], Loss: 500792.9375\n",
            "Epoch [1852/2000], Step [1/3], Loss: 501556.0938\n",
            "Epoch [1853/2000], Step [1/3], Loss: 501302.7188\n",
            "Epoch [1854/2000], Step [1/3], Loss: 500321.6562\n",
            "Epoch [1855/2000], Step [1/3], Loss: 500334.9375\n",
            "Epoch [1856/2000], Step [1/3], Loss: 500503.6250\n",
            "Epoch [1857/2000], Step [1/3], Loss: 500106.2500\n",
            "Epoch [1858/2000], Step [1/3], Loss: 499330.3750\n",
            "Epoch [1859/2000], Step [1/3], Loss: 501259.5938\n",
            "Epoch [1860/2000], Step [1/3], Loss: 503544.7812\n",
            "Epoch [1861/2000], Step [1/3], Loss: 501109.0625\n",
            "Epoch [1862/2000], Step [1/3], Loss: 503684.7188\n",
            "Epoch [1863/2000], Step [1/3], Loss: 498425.5000\n",
            "Epoch [1864/2000], Step [1/3], Loss: 499058.2500\n",
            "Epoch [1865/2000], Step [1/3], Loss: 497760.3438\n",
            "Epoch [1866/2000], Step [1/3], Loss: 497223.1250\n",
            "Epoch [1867/2000], Step [1/3], Loss: 501330.2500\n",
            "Epoch [1868/2000], Step [1/3], Loss: 501079.7500\n",
            "Epoch [1869/2000], Step [1/3], Loss: 499360.0312\n",
            "Epoch [1870/2000], Step [1/3], Loss: 499814.6250\n",
            "Epoch [1871/2000], Step [1/3], Loss: 500823.7812\n",
            "Epoch [1872/2000], Step [1/3], Loss: 500720.7188\n",
            "Epoch [1873/2000], Step [1/3], Loss: 498822.2188\n",
            "Epoch [1874/2000], Step [1/3], Loss: 500650.5000\n",
            "Epoch [1875/2000], Step [1/3], Loss: 499540.5312\n",
            "Epoch [1876/2000], Step [1/3], Loss: 500110.8750\n",
            "Epoch [1877/2000], Step [1/3], Loss: 500542.2812\n",
            "Epoch [1878/2000], Step [1/3], Loss: 498739.4688\n",
            "Epoch [1879/2000], Step [1/3], Loss: 497964.1250\n",
            "Epoch [1880/2000], Step [1/3], Loss: 500125.4688\n",
            "Epoch [1881/2000], Step [1/3], Loss: 498452.4062\n",
            "Epoch [1882/2000], Step [1/3], Loss: 499972.5312\n",
            "Epoch [1883/2000], Step [1/3], Loss: 499039.4375\n",
            "Epoch [1884/2000], Step [1/3], Loss: 501027.4375\n",
            "Epoch [1885/2000], Step [1/3], Loss: 503218.4688\n",
            "Epoch [1886/2000], Step [1/3], Loss: 499158.3125\n",
            "Epoch [1887/2000], Step [1/3], Loss: 499956.1875\n",
            "Epoch [1888/2000], Step [1/3], Loss: 498112.0312\n",
            "Epoch [1889/2000], Step [1/3], Loss: 498645.2188\n",
            "Epoch [1890/2000], Step [1/3], Loss: 499724.5938\n",
            "Epoch [1891/2000], Step [1/3], Loss: 498658.1562\n",
            "Epoch [1892/2000], Step [1/3], Loss: 498207.0000\n",
            "Epoch [1893/2000], Step [1/3], Loss: 499326.6875\n",
            "Epoch [1894/2000], Step [1/3], Loss: 502838.6250\n",
            "Epoch [1895/2000], Step [1/3], Loss: 502509.3438\n",
            "Epoch [1896/2000], Step [1/3], Loss: 500781.7812\n",
            "Epoch [1897/2000], Step [1/3], Loss: 499018.3125\n",
            "Epoch [1898/2000], Step [1/3], Loss: 501011.3125\n",
            "Epoch [1899/2000], Step [1/3], Loss: 500907.0312\n",
            "Epoch [1900/2000], Step [1/3], Loss: 499348.4688\n",
            "Epoch [1901/2000], Step [1/3], Loss: 500554.0938\n",
            "Epoch [1902/2000], Step [1/3], Loss: 500051.4688\n",
            "Epoch [1903/2000], Step [1/3], Loss: 504388.9375\n",
            "Epoch [1904/2000], Step [1/3], Loss: 500150.8438\n",
            "Epoch [1905/2000], Step [1/3], Loss: 496945.6562\n",
            "Epoch [1906/2000], Step [1/3], Loss: 501323.8125\n",
            "Epoch [1907/2000], Step [1/3], Loss: 500679.0000\n",
            "Epoch [1908/2000], Step [1/3], Loss: 499877.9375\n",
            "Epoch [1909/2000], Step [1/3], Loss: 499661.7500\n",
            "Epoch [1910/2000], Step [1/3], Loss: 498849.7812\n",
            "Epoch [1911/2000], Step [1/3], Loss: 501229.9375\n",
            "Epoch [1912/2000], Step [1/3], Loss: 499913.0625\n",
            "Epoch [1913/2000], Step [1/3], Loss: 501113.4375\n",
            "Epoch [1914/2000], Step [1/3], Loss: 498543.3438\n",
            "Epoch [1915/2000], Step [1/3], Loss: 501486.9062\n",
            "Epoch [1916/2000], Step [1/3], Loss: 499018.0312\n",
            "Epoch [1917/2000], Step [1/3], Loss: 500673.0938\n",
            "Epoch [1918/2000], Step [1/3], Loss: 497215.1250\n",
            "Epoch [1919/2000], Step [1/3], Loss: 499292.7812\n",
            "Epoch [1920/2000], Step [1/3], Loss: 499385.4062\n",
            "Epoch [1921/2000], Step [1/3], Loss: 498319.7812\n",
            "Epoch [1922/2000], Step [1/3], Loss: 499909.6562\n",
            "Epoch [1923/2000], Step [1/3], Loss: 501935.9688\n",
            "Epoch [1924/2000], Step [1/3], Loss: 501417.9062\n",
            "Epoch [1925/2000], Step [1/3], Loss: 499779.6562\n",
            "Epoch [1926/2000], Step [1/3], Loss: 500248.3750\n",
            "Epoch [1927/2000], Step [1/3], Loss: 497944.6562\n",
            "Epoch [1928/2000], Step [1/3], Loss: 501290.0000\n",
            "Epoch [1929/2000], Step [1/3], Loss: 499740.4062\n",
            "Epoch [1930/2000], Step [1/3], Loss: 498055.1250\n",
            "Epoch [1931/2000], Step [1/3], Loss: 498705.6250\n",
            "Epoch [1932/2000], Step [1/3], Loss: 500759.1250\n",
            "Epoch [1933/2000], Step [1/3], Loss: 500254.2188\n",
            "Epoch [1934/2000], Step [1/3], Loss: 502723.8750\n",
            "Epoch [1935/2000], Step [1/3], Loss: 501822.8750\n",
            "Epoch [1936/2000], Step [1/3], Loss: 497325.2812\n",
            "Epoch [1937/2000], Step [1/3], Loss: 503600.4062\n",
            "Epoch [1938/2000], Step [1/3], Loss: 498640.9688\n",
            "Epoch [1939/2000], Step [1/3], Loss: 497944.8125\n",
            "Epoch [1940/2000], Step [1/3], Loss: 500122.0625\n",
            "Epoch [1941/2000], Step [1/3], Loss: 498614.5938\n",
            "Epoch [1942/2000], Step [1/3], Loss: 500043.5938\n",
            "Epoch [1943/2000], Step [1/3], Loss: 500857.2812\n",
            "Epoch [1944/2000], Step [1/3], Loss: 499220.1250\n",
            "Epoch [1945/2000], Step [1/3], Loss: 500649.5312\n",
            "Epoch [1946/2000], Step [1/3], Loss: 500133.0938\n",
            "Epoch [1947/2000], Step [1/3], Loss: 499623.0000\n",
            "Epoch [1948/2000], Step [1/3], Loss: 501529.0312\n",
            "Epoch [1949/2000], Step [1/3], Loss: 502572.4062\n",
            "Epoch [1950/2000], Step [1/3], Loss: 499224.0000\n",
            "Epoch [1951/2000], Step [1/3], Loss: 501504.3125\n",
            "Epoch [1952/2000], Step [1/3], Loss: 498306.7188\n",
            "Epoch [1953/2000], Step [1/3], Loss: 502656.0312\n",
            "Epoch [1954/2000], Step [1/3], Loss: 502870.3125\n",
            "Epoch [1955/2000], Step [1/3], Loss: 501214.6875\n",
            "Epoch [1956/2000], Step [1/3], Loss: 500959.4688\n",
            "Epoch [1957/2000], Step [1/3], Loss: 500045.1562\n",
            "Epoch [1958/2000], Step [1/3], Loss: 500073.6250\n",
            "Epoch [1959/2000], Step [1/3], Loss: 499805.4062\n",
            "Epoch [1960/2000], Step [1/3], Loss: 501689.3125\n",
            "Epoch [1961/2000], Step [1/3], Loss: 500956.8438\n",
            "Epoch [1962/2000], Step [1/3], Loss: 497028.8125\n",
            "Epoch [1963/2000], Step [1/3], Loss: 499347.2812\n",
            "Epoch [1964/2000], Step [1/3], Loss: 499888.0625\n",
            "Epoch [1965/2000], Step [1/3], Loss: 499274.3125\n",
            "Epoch [1966/2000], Step [1/3], Loss: 500105.6562\n",
            "Epoch [1967/2000], Step [1/3], Loss: 500990.3125\n",
            "Epoch [1968/2000], Step [1/3], Loss: 500128.0000\n",
            "Epoch [1969/2000], Step [1/3], Loss: 499680.4062\n",
            "Epoch [1970/2000], Step [1/3], Loss: 502595.6250\n",
            "Epoch [1971/2000], Step [1/3], Loss: 500952.9062\n",
            "Epoch [1972/2000], Step [1/3], Loss: 498024.3125\n",
            "Epoch [1973/2000], Step [1/3], Loss: 502468.1562\n",
            "Epoch [1974/2000], Step [1/3], Loss: 503712.3438\n",
            "Epoch [1975/2000], Step [1/3], Loss: 499161.3438\n",
            "Epoch [1976/2000], Step [1/3], Loss: 500356.0000\n",
            "Epoch [1977/2000], Step [1/3], Loss: 499496.8750\n",
            "Epoch [1978/2000], Step [1/3], Loss: 499776.4688\n",
            "Epoch [1979/2000], Step [1/3], Loss: 499831.8125\n",
            "Epoch [1980/2000], Step [1/3], Loss: 498675.5000\n",
            "Epoch [1981/2000], Step [1/3], Loss: 497755.3750\n",
            "Epoch [1982/2000], Step [1/3], Loss: 500064.5000\n",
            "Epoch [1983/2000], Step [1/3], Loss: 498562.8125\n",
            "Epoch [1984/2000], Step [1/3], Loss: 500195.2188\n",
            "Epoch [1985/2000], Step [1/3], Loss: 499169.8750\n",
            "Epoch [1986/2000], Step [1/3], Loss: 500052.5625\n",
            "Epoch [1987/2000], Step [1/3], Loss: 499703.8438\n",
            "Epoch [1988/2000], Step [1/3], Loss: 498787.7500\n",
            "Epoch [1989/2000], Step [1/3], Loss: 502296.8750\n",
            "Epoch [1990/2000], Step [1/3], Loss: 498123.6562\n",
            "Epoch [1991/2000], Step [1/3], Loss: 497415.2812\n",
            "Epoch [1992/2000], Step [1/3], Loss: 496744.1875\n",
            "Epoch [1993/2000], Step [1/3], Loss: 502767.9688\n",
            "Epoch [1994/2000], Step [1/3], Loss: 499453.7188\n",
            "Epoch [1995/2000], Step [1/3], Loss: 500865.0312\n",
            "Epoch [1996/2000], Step [1/3], Loss: 497335.6250\n",
            "Epoch [1997/2000], Step [1/3], Loss: 501961.7812\n",
            "Epoch [1998/2000], Step [1/3], Loss: 500880.4688\n",
            "Epoch [1999/2000], Step [1/3], Loss: 498450.0938\n",
            "Epoch [2000/2000], Step [1/3], Loss: 500304.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvxhE4IwnX9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8ueuGvIfW9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Save generated images\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        generated_images = model.decoder(z).cpu()\n",
        "        save_image(generated_images, os.path.join(sample_dir, 'generated_images-{}.png'.format(epoch+1)))\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), '/content/sample_data/vae_model1.pth')"
      ],
      "metadata": {
        "id": "vOKBUAA55a6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6YtJQ-O5a96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrlivDp45bBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k70bHPxMew90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model -3"
      ],
      "metadata": {
        "id": "v9ice9Glvpdv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g86Uo1gHvoMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkXsUHwzvoO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptCK7R_dvoSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXOu7jdkvoVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in train_generator.filenames:\n",
        "    print(filename)\n"
      ],
      "metadata": {
        "id": "GyoBGwVvexBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjNk-ruteS7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPx2chdzeS-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hCZp7JSpeTBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2Lmkm4FT7ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGOIttfWT7co"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}